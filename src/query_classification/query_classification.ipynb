{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Ollama client\n",
    "client = ollama.Client()\n",
    "\n",
    "# Define model and classification prompt\n",
    "model = \"qwen2.5:1.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Response from Ollama:\n",
      "```json\n",
      "{\n",
      "    \"subject\": \"Data Science courses\",\n",
      "    \"filters\": {\n",
      "        \"type\": \"free/paid/unknown\",\n",
      "        \"level\": \"beginner\",\n",
      "        \"duration\": \"short\"\n",
      "    },\n",
      "    \"query_type\": \"retrieval\"\n",
      "}\n",
      "```\n",
      "\n",
      "✅ Final Parsed Result:\n",
      "{\n",
      "    \"subject\": \"Data Science courses\",\n",
      "    \"filters\": {\n",
      "        \"type\": \"free/paid/unknown\",\n",
      "        \"level\": \"beginner\",\n",
      "        \"duration\": \"short\"\n",
      "    },\n",
      "    \"query_type\": \"retrieval\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def classify_query_ollama(user_query):\n",
    "    \"\"\"Classifies query type and extracts filters dynamically using Qwen.\"\"\"\n",
    "    \n",
    "    # Dynamic prompt (no fixed query)\n",
    "    prompt = f\"\"\"\n",
    "        You are a smart AI assistant specialized in analyzing complex queries.\n",
    "        Your task is to classify the user's query into one of the following categories:\n",
    "        - **Retrieval:** Direct search for facts or topics.\n",
    "        - **Ranking:** Prioritizing or comparing multiple courses.\n",
    "        - **Inference:** Logical reasoning or prerequisites.\n",
    "        - **Multi-Hop:** Complex multi-step logical queries.\n",
    "\n",
    "        ### **Instructions:**  \n",
    "        1. **Break down** the query into smaller sub-questions if possible.  \n",
    "        2. **Identify dependencies** between sub-questions (multi-hop if >1 step).  \n",
    "        3. **Check if any sub-question involves comparison or ranking.**  \n",
    "        4. **Decide** on the final query type **after** reasoning.  \n",
    "\n",
    "        ### **Query:**  \n",
    "        {user_query}\n",
    "\n",
    "        ### **Chain of Thought (Reasoning):**  \n",
    "        1. What is the main goal of this query?  \n",
    "        2. Are there multiple logical steps or sub-questions?  \n",
    "        3. Is there a ranking or comparison required?  \n",
    "        4. Is logical inference or multi-hop reasoning needed?\n",
    "\n",
    "        ### **Final JSON Output:**  \n",
    "        Return ONLY a JSON object:\n",
    "        ```json\n",
    "        {{\n",
    "        \"subject\": \"<subject>\",\n",
    "        \"filters\": {{\n",
    "            \"type\": \"<free/paid/unknown>\",\n",
    "            \"level\": \"<beginner/intermediate/advanced/unknown>\",\n",
    "            \"duration\": \"<short/long/unknown>\"\n",
    "        }},\n",
    "        \"query_type\": \"<retrieval/ranking/inference/multi-hop/unknown>\"\n",
    "        }}\"\"\"\n",
    "    \n",
    "    # Generate response from Ollama\n",
    "    response = client.generate(model=model, prompt=prompt)\n",
    "    print(\"Raw Response from Ollama:\")\n",
    "    print(response.response)\n",
    "\n",
    "    # Clean response: Remove backticks and whitespace\n",
    "    cleaned_response = re.sub(r'```json|```', '', response.response).strip()\n",
    "\n",
    "    # Parse JSON safely\n",
    "    try:\n",
    "        parsed_response = json.loads(cleaned_response)\n",
    "        return parsed_response\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"\\n❌ Error: Invalid JSON format.\")\n",
    "        print(f\"Error Details: {e}\")\n",
    "        return {\"error\": \"Invalid JSON format\", \"response\": cleaned_response}\n",
    "\n",
    "# Example Usage (Dynamic Query)\n",
    "user_query = \"Which course is suitable for beginners in Data Science?\"\n",
    "result = classify_query_ollama(user_query)\n",
    "print(\"\\n✅ Final Parsed Result:\")\n",
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🗂️ Query: List all free Python courses.\n",
      "\n",
      "🔍 Raw Response from Qwen:\n",
      "```json\n",
      "{\n",
      "    \"subject\": \"Python courses\",\n",
      "    \"filters\": {\n",
      "        \"type\": \"free\",\n",
      "        \"level\": \"beginner\",\n",
      "        \"duration\": \"unknown\"\n",
      "    },\n",
      "    \"query_type\": \"retrieval\"\n",
      "}\n",
      "```\n",
      "\n",
      "✅ Final Parsed Result:\n",
      "{\n",
      "    \"subject\": \"Python courses\",\n",
      "    \"filters\": {\n",
      "        \"type\": \"free\",\n",
      "        \"level\": \"beginner\",\n",
      "        \"duration\": \"unknown\"\n",
      "    },\n",
      "    \"query_type\": \"retrieval\"\n",
      "}\n",
      "\n",
      "🗂️ Query: Which is better: Course A or Course B?\n",
      "\n",
      "🔍 Raw Response from Qwen:\n",
      "```json\n",
      "{\n",
      "    \"subject\": \"Compare Course A and Course B\",\n",
      "    \"filters\": {\n",
      "        \"type\": \"Unknown\",\n",
      "        \"level\": \"Unknown\",\n",
      "        \"duration\": \"Unknown\"\n",
      "    },\n",
      "    \"query_type\": \"Multi-Hop\"\n",
      "}\n",
      "```\n",
      "\n",
      "✅ Final Parsed Result:\n",
      "{\n",
      "    \"subject\": \"Compare Course A and Course B\",\n",
      "    \"filters\": {\n",
      "        \"type\": \"Unknown\",\n",
      "        \"level\": \"Unknown\",\n",
      "        \"duration\": \"Unknown\"\n",
      "    },\n",
      "    \"query_type\": \"Multi-Hop\"\n",
      "}\n",
      "\n",
      "🗂️ Query: What are the prerequisites for an advanced AI course?\n",
      "\n",
      "🔍 Raw Response from Qwen:\n",
      "```json\n",
      "{\n",
      "    \"subject\": \"AI course prerequisites\",\n",
      "    \"filters\": {\n",
      "        \"type\": \"advanced\",\n",
      "        \"level\": \"advanced\",\n",
      "        \"duration\": \"unknown\"\n",
      "    },\n",
      "    \"query_type\": \"inference\"\n",
      "}\n",
      "```\n",
      "\n",
      "✅ Final Parsed Result:\n",
      "{\n",
      "    \"subject\": \"AI course prerequisites\",\n",
      "    \"filters\": {\n",
      "        \"type\": \"advanced\",\n",
      "        \"level\": \"advanced\",\n",
      "        \"duration\": \"unknown\"\n",
      "    },\n",
      "    \"query_type\": \"inference\"\n",
      "}\n",
      "\n",
      "🗂️ Query: Find a course that teaches Python and covers machine learning.\n",
      "\n",
      "🔍 Raw Response from Qwen:\n",
      "```json\n",
      "{\n",
      "  \"subject\": \"Python\",\n",
      "  \"filters\": {\n",
      "    \"type\": \"free/paid/unknown\",\n",
      "    \"level\": \"beginner/intermediate/advanced/unknown\",\n",
      "    \"duration\": \"short/long/unknown\"\n",
      "  },\n",
      "  \"query_type\": \"inference/multi-hop\"\n",
      "}\n",
      "```\n",
      "\n",
      "✅ Final Parsed Result:\n",
      "{\n",
      "    \"subject\": \"Python\",\n",
      "    \"filters\": {\n",
      "        \"type\": \"free/paid/unknown\",\n",
      "        \"level\": \"beginner/intermediate/advanced/unknown\",\n",
      "        \"duration\": \"short/long/unknown\"\n",
      "    },\n",
      "    \"query_type\": \"inference/multi-hop\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def classify_query_qwen(user_query):\n",
    "    \"\"\"Classifies query type and extracts filters dynamically using Qwen.\"\"\"\n",
    "    \n",
    "    # Dynamic prompt for Qwen\n",
    "    prompt = f\"\"\"\n",
    "        You are a smart AI assistant specialized in analyzing complex queries.\n",
    "        Your task is to classify the user's query into one of the following categories:\n",
    "        - **Retrieval:** Direct search for facts or topics.\n",
    "        - **Ranking:** Prioritizing or comparing multiple courses.\n",
    "        - **Inference:** Logical reasoning or prerequisites.\n",
    "        - **Multi-Hop:** Complex multi-step logical queries.\n",
    "\n",
    "        ### **Instructions:**  \n",
    "        1. **Break down** the query into smaller sub-questions if possible.  \n",
    "        2. **Identify dependencies** between sub-questions (multi-hop if >1 step).  \n",
    "        3. **Check if any sub-question involves comparison or ranking.**  \n",
    "        4. **Decide** on the final query type **after** reasoning.  \n",
    "\n",
    "        ### **Query:**  \n",
    "        {user_query}\n",
    "\n",
    "        ### **Chain of Thought (Reasoning):**  \n",
    "        1. What is the main goal of this query?  \n",
    "        2. Are there multiple logical steps or sub-questions?  \n",
    "        3. Is there a ranking or comparison required?  \n",
    "        4. Is logical inference or multi-hop reasoning needed?  \n",
    "\n",
    "        ### **Final JSON Output:**  \n",
    "        Return ONLY a JSON object:\n",
    "        ```json\n",
    "        {{\n",
    "        \"subject\": \"<subject>\",\n",
    "        \"filters\": {{\n",
    "            \"type\": \"<free/paid/unknown>\",\n",
    "            \"level\": \"<beginner/intermediate/advanced/unknown>\",\n",
    "            \"duration\": \"<short/long/unknown>\"\n",
    "        }},\n",
    "        \"query_type\": \"<retrieval/ranking/inference/multi-hop/unknown>\"\n",
    "        }}\"\"\"\n",
    "    \n",
    "    # Call Qwen API\n",
    "    response = client.generate(model=model, prompt=prompt)\n",
    "\n",
    "    print(\"\\n🔍 Raw Response from Qwen:\")\n",
    "    print(response.response)\n",
    "\n",
    "    # Clean response\n",
    "    cleaned_response = re.sub(r'```json|```', '', response.response).strip()\n",
    "\n",
    "    # Safely parse JSON\n",
    "    try:\n",
    "        parsed_response = json.loads(cleaned_response)\n",
    "        return parsed_response\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"\\n❌ Error: Invalid JSON format.\")\n",
    "        print(f\"Error Details: {e}\")\n",
    "        return {\"error\": \"Invalid JSON format\", \"response\": cleaned_response}\n",
    "\n",
    "# Example Queries\n",
    "queries = [\n",
    "    \"List all free Python courses.\",\n",
    "    \"Which is better: Course A or Course B?\",\n",
    "    \"What are the prerequisites for an advanced AI course?\",\n",
    "    \"Find a course that teaches Python and covers machine learning.\"\n",
    "]\n",
    "\n",
    "# Testing Each Query\n",
    "for q in queries:\n",
    "    print(f\"\\n🗂️ Query: {q}\")\n",
    "    result = classify_query_qwen(q)\n",
    "    print(\"\\n✅ Final Parsed Result:\")\n",
    "    print(json.dumps(result, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw Response from Qwen:\n",
      "```json\n",
      "{\n",
      "  \"subject\": \"Data Science\",\n",
      "  \"filters\": {\n",
      "    \"type\": \"programming\",\n",
      "    \"level\": \"intermediate\",\n",
      "    \"duration\": \"long\"\n",
      "  },\n",
      "  \"query_type\": \"inference\"\n",
      "}\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'subject': 'Data Science',\n",
       " 'filters': {'type': 'programming',\n",
       "  'level': 'intermediate',\n",
       "  'duration': 'long'},\n",
       " 'query_type': 'inference'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = \"I have 3 months studying data science field with nothing about statistical, which course should i study to has deeper knowledge on statistical?\"\n",
    "result = classify_query_qwen(user_query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS index built with 8092 courses.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load courses data\n",
    "with open(\"D:\\\\Thesis\\\\Courses-Searching\\\\src\\\\db\\\\processed_courses_detail.json\", \"r\") as f:\n",
    "    courses = json.load(f)\n",
    "\n",
    "# Initialize SBERT model\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def combine_course_text(course):\n",
    "    \"\"\"Creates a combined text from multiple relevant fields.\"\"\"\n",
    "    # Extract key fields\n",
    "    title = course.get(\"title\", \"\") or \"\"\n",
    "    description = course.get(\"description\", \"\") or \"\"\n",
    "    skills = \", \".join(course.get(\"knowledge_requirements\", {}).get(\"teaches\") or [])\n",
    "    category = course.get(\"category\", \"\") or \"\"\n",
    "    sub_category = course.get(\"sub_category\", \"\") or \"\"\n",
    "    instructors = \", \".join(course.get(\"instructors\") or [])\n",
    "    provider = course.get(\"course_info\", {}).get(\"provider\", \"\") or \"\"\n",
    "    duration = str(course.get(\"duration_months\") or \"\")\n",
    "    \n",
    "    # Combine into one text string\n",
    "    combined_text = f\"\"\"\n",
    "    Title: {title}.\n",
    "    Description: {description}.\n",
    "    Skills: {skills}.\n",
    "    Category: {category}, {sub_category}.\n",
    "    Instructors: {instructors}.\n",
    "    Provider: {provider}.\n",
    "    Duration: {duration} months.\n",
    "    \"\"\"\n",
    "    \n",
    "    return combined_text\n",
    "\n",
    "# Create embeddings for all courses\n",
    "course_texts = [combine_course_text(course) for course in courses]\n",
    "embeddings = embedding_model.encode(course_texts, convert_to_numpy=True)\n",
    "\n",
    "# Create FAISS index\n",
    "dimension = embeddings.shape[1]\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "faiss_index.add(embeddings)\n",
    "faiss.write_index(faiss_index, \"faiss_course_index_full.bin\")\n",
    "\n",
    "print(f\"✅ FAISS index built with {len(course_texts)} courses.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 5 courses.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Load FAISS index\n",
    "faiss_index = faiss.read_index(\"faiss_course_index_full.bin\")\n",
    "\n",
    "# Quick Test: Semantic Search\n",
    "def semantic_search(query_text, top_k=10):\n",
    "    \"\"\"Performs semantic search on FAISS index using SBERT.\"\"\"\n",
    "    query_embedding = embedding_model.encode([query_text], convert_to_numpy=True)\n",
    "    distances, indices = faiss_index.search(query_embedding, top_k)\n",
    "    \n",
    "    # Retrieve results\n",
    "    results = [courses[i] for i in indices[0]]\n",
    "    return results\n",
    "\n",
    "# Example Test\n",
    "results = semantic_search(\"Beginner Data Science courses\", top_k=5)\n",
    "print(f\"Retrieved {len(results)} courses.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 5 courses:\n",
      "\n",
      "1. Python 3 Programming Specialization - 4.7⭐\n",
      "   URL: https://www.coursera.org/specializations/python-3-programming\n",
      "   Duration: 5.0 months\n",
      "   Suitable for: Advanced Learners\n",
      "2. Python for Command-and-control, Exfiltration and Impact - 4.6⭐\n",
      "   URL: https://www.coursera.org/learn/command-and-control-exfiltration-and-impact?specialization=pythonforcybersecurity\n",
      "   Duration: 3.0 months\n",
      "   Suitable for: Advanced Learners\n",
      "3. Introduction to Python Programming - 4.4⭐\n",
      "   URL: https://www.coursera.org/learn/python-programming-intro\n",
      "   Duration: 27.0 months\n",
      "   Suitable for: Advanced Learners\n",
      "4. Python Certification Course - None⭐\n",
      "   URL: https://www.simplilearn.com/mobile-and-software-development/python-development-training?tag=\n",
      "   Duration: None months\n",
      "   Suitable for: Advanced Learners\n",
      "5. Learn Intermediate Python - None⭐\n",
      "   URL: https://www.udacity.com/course/intermediate-python-nanodegree--nd303\n",
      "   Duration: 2.0 months\n",
      "   Suitable for: Advanced Learners\n"
     ]
    }
   ],
   "source": [
    "results = semantic_search(\"What are the top 3 Python courses?\", top_k=5)\n",
    "#results\n",
    "def rank_courses_advanced(courses):\n",
    "    \"\"\"Ranks courses considering rating, reviews, duration, and metadata completeness.\"\"\"\n",
    "    def score(course):\n",
    "        # Extract features\n",
    "        rating = course.get('rating') or 0  # Default to 0 if None\n",
    "        reviews = course.get('reviews', {}).get('total_reviews') or 0\n",
    "        duration = course.get('duration_months') or 0\n",
    "        \n",
    "        # 1. Penalize missing ratings more severely\n",
    "        rating_penalty = 0.1 if rating == 0 else 1.0  # Drastic penalty for None\n",
    "        \n",
    "        # 2. Penalize excessively long courses (>12 months)\n",
    "        duration_penalty = 1 if duration <= 12 else 1 / (1 + (duration - 12) * 0.2)\n",
    "        \n",
    "        # 3. Boost popular courses with more reviews\n",
    "        popularity = min(reviews, 1000) / 1000  # Capped at 1000\n",
    "        \n",
    "        # Final composite score\n",
    "        return ((rating * 0.6 + popularity * 0.4) * \n",
    "                duration_penalty * rating_penalty)\n",
    "    \n",
    "    # Sort by final score\n",
    "    return sorted(courses, key=score, reverse=True)\n",
    "\n",
    "# Apply the updated ranking\n",
    "ranked_courses = rank_courses_advanced(results)\n",
    "\n",
    "\n",
    "def fill_missing_metadata(course):\n",
    "    \"\"\"Fills missing fields with defaults.\"\"\"\n",
    "    course['rating'] = course.get('rating', 0)  # Set to 0 if missing\n",
    "    course['course_info']['language'] = course['course_info'].get('language', 'Unknown')\n",
    "    course['category'] = course.get('category', 'General')\n",
    "    return course\n",
    "\n",
    "# Apply to all results\n",
    "results = [fill_missing_metadata(c) for c in ranked_courses]\n",
    "def remove_duplicates(courses):\n",
    "    \"\"\"Removes duplicate courses based on title or course ID.\"\"\"\n",
    "    seen = set()\n",
    "    unique_courses = []\n",
    "    for course in courses:\n",
    "        if course['title'] not in seen:\n",
    "            unique_courses.append(course)\n",
    "            seen.add(course['title'])\n",
    "    return unique_courses\n",
    "\n",
    "# Remove duplicates before final output\n",
    "unique_ranked_courses = remove_duplicates(ranked_courses)\n",
    "\n",
    "def semantic_rerank(query, results):\n",
    "    \"\"\"Reranks results by semantic similarity, prioritizing title and skills.\"\"\"\n",
    "    result_texts = []\n",
    "    for r in results:\n",
    "        title = r.get('title', \"\") or \"\"\n",
    "        description = r.get('description', \"\") or \"\"\n",
    "        skills = \", \".join(r.get('knowledge_requirements', {}).get('teaches', []) or [])\n",
    "        \n",
    "        # Prioritize title and skills more\n",
    "        combined_text = f\"{title} {skills} {description}\"\n",
    "        result_texts.append(combined_text)\n",
    "    \n",
    "    # Encode query and results\n",
    "    query_embedding = embedding_model.encode([query], convert_to_numpy=True)\n",
    "    result_embeddings = embedding_model.encode(result_texts, convert_to_numpy=True)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    scores = np.dot(result_embeddings, query_embedding.T).flatten()\n",
    "    \n",
    "    # Sort by similarity score\n",
    "    ranked = [r for _, r in sorted(zip(scores, results), reverse=True)]\n",
    "    return ranked\n",
    "\n",
    "\n",
    "# Re-rank the current results\n",
    "reranked_courses = semantic_rerank(\"Getting started with statistical\", unique_ranked_courses)\n",
    "\n",
    "\n",
    "def format_output(courses):\n",
    "    \"\"\"Formats the final ranked list for output.\"\"\"\n",
    "    if not courses:\n",
    "        return \"No courses match your criteria.\"\n",
    "\n",
    "    response = f\"✅ Found {len(courses)} courses:\\n\"\n",
    "    for i, course in enumerate(courses[:5], 1):  # Show top 5 results\n",
    "        response += f\"\\n{i}. {course['title']} - {course['rating']}⭐\"\n",
    "        response += f\"\\n   URL: {course['url']}\"\n",
    "        response += f\"\\n   Duration: {course['duration_months']} months\"\n",
    "        response += f\"\\n   Suitable for: {', '.join(course['learning_path']['suitable_for'])}\"\n",
    "    return response\n",
    "\n",
    "# Final formatted output\n",
    "print(format_output(unique_ranked_courses))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "\n",
    "# Initialize Ollama client\n",
    "client = ollama.Client()\n",
    "model = \"qwen2.5:1.5b\"\n",
    "\n",
    "def generate_inference_prompt(query, course):\n",
    "    \"\"\"Generates a prompt for Qwen to infer relevant details.\"\"\"\n",
    "    return f\"\"\"\n",
    "    Analyze the following course and the user query. \n",
    "    \n",
    "    **Course Details:**\n",
    "    Title: {course['title']}\n",
    "    Description: {course['description']}\n",
    "    Skills Taught: {', '.join(course.get('knowledge_requirements', {}).get('teaches', []))}\n",
    "    Prerequisites: {', '.join(course.get('knowledge_requirements', {}).get('prerequisites', []))}\n",
    "    Duration: {course.get('duration_months', 'Unknown')} months\n",
    "    Rating: {course.get('rating', 'Unknown')}\n",
    "    Suitable For: {', '.join(course.get('learning_path', {}).get('suitable_for', []))}\n",
    "    Career Paths: {', '.join(course.get('learning_path', {}).get('career_paths', []))}\n",
    "    \n",
    "    **User Query:** \"{query}\"\n",
    "    \n",
    "    **Task:** \n",
    "    - Determine if this course satisfies the user's query.\n",
    "    - If the query involves difficulty, infer the level (beginner/intermediate/advanced).\n",
    "    - If the query involves prerequisites, list the skills required.\n",
    "    - If the query involves suitability, decide whether the course fits the career or skill needs.\n",
    "    - If temporal reasoning is needed, explain the sequence of topics.\n",
    "\n",
    "    Output ONLY a JSON object with this structure:\n",
    "    {{\n",
    "      \"match\": \"<yes/no>\",\n",
    "      \"difficulty\": \"<beginner/intermediate/advanced or None>\",\n",
    "      \"suitability\": \"<suitable/not suitable>\",\n",
    "      \"prerequisites\": \"<list of prerequisites or None>\",\n",
    "      \"temporal_info\": \"<before/after/None>\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "### **3. General Inference Function:**  \n",
    "\n",
    "def perform_inference(query, courses):\n",
    "    \"\"\"Performs inference on multiple courses using Qwen.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for course in courses:\n",
    "        prompt = generate_inference_prompt(query, course)\n",
    "        response = client.generate(model=model, prompt=prompt)\n",
    "        \n",
    "        try:\n",
    "            # Parse JSON response\n",
    "            parsed_response = json.loads(response.response)\n",
    "            # Add course ID to response for tracking\n",
    "            parsed_response[\"course_id\"] = course[\"course_id\"]\n",
    "            parsed_response[\"title\"] = course[\"title\"]\n",
    "            results.append(parsed_response)\n",
    "        except json.JSONDecodeError:\n",
    "            # Handle parsing errors\n",
    "            results.append({\n",
    "                \"course_id\": course[\"course_id\"],\n",
    "                \"title\": course[\"title\"],\n",
    "                \"error\": \"Invalid JSON response\"\n",
    "            })\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m     courses \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Perform Inference\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m inference_results \u001b[38;5;241m=\u001b[39m \u001b[43mperform_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcourses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Output sample results\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(inference_results[:\u001b[38;5;241m3\u001b[39m], indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))  \u001b[38;5;66;03m# Show first 3 responses\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 52\u001b[0m, in \u001b[0;36mperform_inference\u001b[1;34m(query, courses)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m course \u001b[38;5;129;01min\u001b[39;00m courses:\n\u001b[0;32m     51\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m generate_inference_prompt(query, course)\n\u001b[1;32m---> 52\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;66;03m# Parse JSON response\u001b[39;00m\n\u001b[0;32m     56\u001b[0m         parsed_response \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mresponse)\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\ollama\\_client.py:242\u001b[0m, in \u001b[0;36mClient.generate\u001b[1;34m(self, model, prompt, suffix, system, template, context, stream, raw, format, images, options, keep_alive)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    218\u001b[0m   model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    231\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[GenerateResponse, Iterator[GenerateResponse]]:\n\u001b[0;32m    232\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m  Create a response using the requested model.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m  Returns `GenerateResponse` if `stream` is `False`, otherwise returns a `GenerateResponse` generator.\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mGenerateResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/generate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGenerateRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m      \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m      \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m      \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m      \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m      \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\ollama\\_client.py:178\u001b[0m, in \u001b[0;36mClient._request\u001b[1;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpart)\n\u001b[0;32m    176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\ollama\\_client.py:118\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    117\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\httpx\\_client.py:827\u001b[0m, in \u001b[0;36mClient.request\u001b[1;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[0;32m    812\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m    814\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[0;32m    815\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    816\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    825\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[0;32m    826\u001b[0m )\n\u001b[1;32m--> 827\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[0;32m    910\u001b[0m )\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\httpx\\_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1012\u001b[0m     )\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\httpx\\_transports\\default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    231\u001b[0m )\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    242\u001b[0m )\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\httpcore\\_sync\\http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\httpcore\\_sync\\http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    107\u001b[0m     (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m         trailing_data,\n\u001b[1;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m         http_version,\n\u001b[0;32m    116\u001b[0m         status,\n\u001b[0;32m    117\u001b[0m         reason_phrase,\n\u001b[0;32m    118\u001b[0m         headers,\n\u001b[0;32m    119\u001b[0m     )\n\u001b[0;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\httpcore\\_sync\\http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example Query\n",
    "user_query = \"What are some beginner-friendly AI courses with no prerequisites?\"\n",
    "\n",
    "# Load processed courses data\n",
    "with open(\"D:\\\\Thesis\\\\Courses-Searching\\\\src\\\\db\\\\processed_courses_detail.json\", \"r\") as f:\n",
    "    courses = json.load(f)\n",
    "\n",
    "# Perform Inference\n",
    "inference_results = perform_inference(user_query, courses)\n",
    "\n",
    "# Output sample results\n",
    "print(json.dumps(inference_results[:3], indent=4))  # Show first 3 responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"course_id\": \"Ccd34bc1e\",\n",
      "        \"course_title\": \"Machine Learning Specialization\",\n",
      "        \"match\": \"Yes\",\n",
      "        \"difficulty\": \"beginner\",\n",
      "        \"prerequisites\": [\n",
      "            \"Decision Trees\",\n",
      "            \"Artificial Neural Network\",\n",
      "            \"Logistic Regression\"\n",
      "        ],\n",
      "        \"suitability\": \"career\"\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"Ca68e750c\",\n",
      "        \"course_title\": \"Introduction to Data Science Specialization\",\n",
      "        \"match\": \"Yes\",\n",
      "        \"difficulty\": \"intermediate/advanced\",\n",
      "        \"prerequisites\": [\n",
      "            \"Data Science\",\n",
      "            \"Relational Database Management System (RDBMS)\",\n",
      "            \"Cloud Databases\"\n",
      "        ],\n",
      "        \"suitability\": \"career\"\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"C43ba268c\",\n",
      "        \"course_title\": \"Data Science Fundamentals with Python and SQL Specialization\",\n",
      "        \"match\": \"Yes\",\n",
      "        \"difficulty\": \"beginner/intermediate\",\n",
      "        \"prerequisites\": [\n",
      "            \"Data Science\",\n",
      "            \"Github\",\n",
      "            \"Python Programming\"\n",
      "        ],\n",
      "        \"suitability\": \"career\"\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"C900e581d\",\n",
      "        \"course_title\": \"Key Technologies for Business Specialization\",\n",
      "        \"match\": \"Yes\",\n",
      "        \"difficulty\": \"beginner/intermediate\",\n",
      "        \"prerequisites\": [\n",
      "            \"Data Science\",\n",
      "            \"Artificial Intelligence (AI)\",\n",
      "            \"Business\"\n",
      "        ],\n",
      "        \"suitability\": \"career\"\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"C4a7fec04\",\n",
      "        \"course_title\": \"Deep Learning Specialization\",\n",
      "        \"match\": \"Yes\",\n",
      "        \"difficulty\": \"beginner/intermediate\",\n",
      "        \"prerequisites\": [\n",
      "            \"Artificial Neural Network\",\n",
      "            \"Convolutional Neural Network\",\n",
      "            \"Tensorflow\"\n",
      "        ],\n",
      "        \"suitability\": \"career\"\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"C3f5239d2\",\n",
      "        \"course_title\": \"IBM & Darden Digital Strategy Specialization\",\n",
      "        \"match\": \"no\",\n",
      "        \"difficulty\": null,\n",
      "        \"prerequisites\": [\n",
      "            \"Data Science\",\n",
      "            \"Digital transformation\",\n",
      "            \"Artificial Intelligence (AI)\"\n",
      "        ],\n",
      "        \"suitability\": null\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"C51f53378\",\n",
      "        \"course_title\": \"IBM AI Foundations for Business Specialization\",\n",
      "        \"match\": \"no\",\n",
      "        \"difficulty\": null,\n",
      "        \"prerequisites\": [\n",
      "            \"Data Science\",\n",
      "            \"Artificial Intelligence (AI)\",\n",
      "            \"Information Technology (IT) Architecture\"\n",
      "        ],\n",
      "        \"suitability\": null\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"C622e5c26\",\n",
      "        \"course_title\": \"Data Analysis and Visualization Foundations Specialization\",\n",
      "        \"match\": \"no\",\n",
      "        \"difficulty\": null,\n",
      "        \"prerequisites\": [\n",
      "            \"Data Science\",\n",
      "            \"Spreadsheet\",\n",
      "            \"Microsoft Excel\"\n",
      "        ],\n",
      "        \"suitability\": null\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"C2e4d7943\",\n",
      "        \"course_title\": \"Applied Data Science Specialization\",\n",
      "        \"match\": \"no\",\n",
      "        \"difficulty\": null,\n",
      "        \"prerequisites\": [\n",
      "            \"Data Science\",\n",
      "            \"Python Programming\",\n",
      "            \"Data Analysis\"\n",
      "        ],\n",
      "        \"suitability\": null\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"Cdfa6b83e\",\n",
      "        \"course_title\": \"Data Engineering Foundations Specialization\",\n",
      "        \"match\": \"no\",\n",
      "        \"difficulty\": null,\n",
      "        \"prerequisites\": [\n",
      "            \"Information Engineering\",\n",
      "            \"Python Programming\",\n",
      "            \"Extraction\"\n",
      "        ],\n",
      "        \"suitability\": null\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"C32d89f68\",\n",
      "        \"course_title\": \"IT Fundamentals for Cybersecurity Specialization\",\n",
      "        \"match\": \"no\",\n",
      "        \"difficulty\": null,\n",
      "        \"prerequisites\": [\n",
      "            \"Operating System Security\",\n",
      "            \"database vulnerabilities\",\n",
      "            \"Cybersecurity\"\n",
      "        ],\n",
      "        \"suitability\": null\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"C093e071b\",\n",
      "        \"course_title\": \"Applied Software Engineering Fundamentals Specialization\",\n",
      "        \"match\": \"no\",\n",
      "        \"difficulty\": null,\n",
      "        \"prerequisites\": [\n",
      "            \"Linux\",\n",
      "            \"Software Design and Architecture\",\n",
      "            \"Python Programming\"\n",
      "        ],\n",
      "        \"suitability\": null\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"Cd8e6d1d6\",\n",
      "        \"course_title\": \"DevOps, Cloud, and Agile Foundations Specialization\",\n",
      "        \"match\": \"no\",\n",
      "        \"difficulty\": null,\n",
      "        \"prerequisites\": [\n",
      "            \"Cloud Native\",\n",
      "            \"Devops\",\n",
      "            \"Scrum\"\n",
      "        ],\n",
      "        \"suitability\": null\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"C335c9825\",\n",
      "        \"course_title\": \"Cloud Application Development Foundations Specialization\",\n",
      "        \"match\": \"no\",\n",
      "        \"difficulty\": null,\n",
      "        \"prerequisites\": [\n",
      "            \"Devops\",\n",
      "            \"Python Programming\",\n",
      "            \"Node.Js\"\n",
      "        ],\n",
      "        \"suitability\": null\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"C006c6b75\",\n",
      "        \"course_title\": \"Python for Everybody Specialization\",\n",
      "        \"match\": \"yes\",\n",
      "        \"difficulty\": \"beginner\",\n",
      "        \"prerequisites\": [\n",
      "            \"Json\",\n",
      "            \"Xml\",\n",
      "            \"Python Programming\"\n",
      "        ],\n",
      "        \"suitability\": \"Yes\"\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"Cdcea2195\",\n",
      "        \"course_title\": \"Information Technology (IT) and Cloud Fundamentals Specialization\",\n",
      "        \"match\": null,\n",
      "        \"difficulty\": \"beginner\",\n",
      "        \"prerequisites\": [\n",
      "            \"IT Fundamentals\",\n",
      "            \"Cybersecurity\",\n",
      "            \"Cloud\"\n",
      "        ],\n",
      "        \"suitability\": \"yes\"\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"C18933607\",\n",
      "        \"course_title\": \"BI Foundations with SQL, ETL and Data Warehousing Specialization\",\n",
      "        \"match\": null,\n",
      "        \"difficulty\": \"beginner\",\n",
      "        \"prerequisites\": [\n",
      "            \"Shell Script\",\n",
      "            \"Bash (Unix Shell)\",\n",
      "            \"Linux\"\n",
      "        ],\n",
      "        \"suitability\": \"yes\"\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"Cda58616c\",\n",
      "        \"course_title\": \"Natural Language Processing Specialization\",\n",
      "        \"match\": null,\n",
      "        \"difficulty\": \"beginner\",\n",
      "        \"prerequisites\": [\n",
      "            \"Word2vec\",\n",
      "            \"Machine Translation\",\n",
      "            \"Sentiment Analysis\"\n",
      "        ],\n",
      "        \"suitability\": \"yes\"\n",
      "    },\n",
      "    {\n",
      "        \"course_id\": \"C7f2de105\",\n",
      "        \"course_title\": \"Meta React Native Specialization\",\n",
      "        \"match\": null,\n",
      "        \"difficulty\": \"beginner\",\n",
      "        \"prerequisites\": [\n",
      "            \"Web Development\",\n",
      "            \"React (Web Framework)\",\n",
      "            \"HTML and CSS\"\n",
      "        ],\n",
      "        \"suitability\": \"yes\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "def generate_batch_prompt(query, courses):\n",
    "    \"\"\"Generates a batch prompt for multiple courses with stricter JSON enforcement.\"\"\"\n",
    "    course_descriptions = \"\"\n",
    "    for course in courses:\n",
    "        course_descriptions += f\"\"\"\n",
    "        - Course ID: {course['course_id']}\n",
    "        - Title: {course['title']}\n",
    "        - Description: {course['description'][:100]}...\n",
    "        - Skills: {', '.join(course.get('knowledge_requirements', {}).get('teaches', []) or [])}\n",
    "        - Prerequisites: {', '.join(course.get('knowledge_requirements', {}).get('prerequisites', []) or [])}\n",
    "        - Duration: {course.get('duration_months', 'Unknown')} months\n",
    "        - Rating: {course.get('rating', 'Unknown')}\n",
    "        \"\"\"\n",
    "    \n",
    "    return f\"\"\"\n",
    "    **User Query:** \"{query}\"\n",
    "    \n",
    "    **Courses:** \n",
    "    {course_descriptions}\n",
    "    \n",
    "    **Task:** \n",
    "    1. For each course, determine:\n",
    "       - If it fits the user query.\n",
    "       - Difficulty (beginner/intermediate/advanced) - 1 in those 3.\n",
    "       - Prerequisites (if any. if query request no prerequisites, retrieve courses with no prerequisites).\n",
    "       - Suitability for career or skill goals.\n",
    "    \n",
    "    **IMPORTANT:**  \n",
    "    - ONLY output a valid JSON object.\n",
    "    - DO NOT include any text outside the JSON.\n",
    "    - If a field is missing, use **null** instead of leaving it empty.\n",
    "\n",
    "    **Final JSON format:**  \n",
    "    ```json\n",
    "    {{\n",
    "        \"results\": [\n",
    "            {{\n",
    "                \"course_id\": \"<course_id>\",\n",
    "                \"course_title\": \"<title>\",\n",
    "                \"match\": \"<yes/no>\",\n",
    "                \"difficulty\": \"<beginner/intermediate/advanced>\",\n",
    "                \"prerequisites\": [\"<prerequisite1>\", \"<prerequisite2>\"] or null,\n",
    "                \"suitability\": \"<yes/no>\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "## 🚀 **4. Add a Safe JSON Parsing Function:**\n",
    "\n",
    "import json\n",
    "import ollama\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Initialize Ollama client\n",
    "client = ollama.Client()\n",
    "model = \"qwen2.5:1.5b\"\n",
    "\n",
    "def safe_json_parse(response_text):\n",
    "    \"\"\"Tries to safely extract a JSON block from response text.\"\"\"\n",
    "    try:\n",
    "        # Look for the first valid JSON block\n",
    "        json_start = response_text.find(\"{\")\n",
    "        json_end = response_text.rfind(\"}\") + 1\n",
    "        json_str = response_text[json_start:json_end]\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"error\": \"Invalid JSON response\", \"raw_response\": response_text}\n",
    "\n",
    "def perform_batch_inference(query, courses, batch_size=5):\n",
    "    \"\"\"Performs batch inference using Qwen with parallel execution.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Divide courses into batches\n",
    "    batches = [courses[i:i + batch_size] for i in range(0, len(courses), batch_size)]\n",
    "    \n",
    "    def run_batch(batch):\n",
    "        \"\"\"Runs inference on a batch of courses.\"\"\"\n",
    "        prompt = generate_batch_prompt(query, batch)\n",
    "        response = client.generate(model=model, prompt=prompt)\n",
    "        \n",
    "        # Parse response safely\n",
    "        parsed = safe_json_parse(response.response)\n",
    "        return parsed.get(\"results\", [{\"error\": \"No valid JSON extracted\"}])\n",
    "    \n",
    "    # Run batches in parallel\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        future_to_batch = {executor.submit(run_batch, batch): batch for batch in batches}\n",
    "        \n",
    "        for future in future_to_batch:\n",
    "            try:\n",
    "                batch_result = future.result()\n",
    "                results.extend(batch_result)\n",
    "            except Exception as e:\n",
    "                results.append({\"error\": str(e)})\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "## 🏃‍♂️ **5. Run Inference Again:**\n",
    "# Example Query\n",
    "user_query = \"Find beginner-level data science courses with no prerequisites.\"\n",
    "\n",
    "# Load processed courses data\n",
    "with open(\"D:\\\\Thesis\\\\Courses-Searching\\\\src\\\\db\\\\processed_courses_detail.json\", \"r\") as f:\n",
    "    courses = json.load(f)\n",
    "\n",
    "# Limit to top 20 for speed (or use FAISS to reduce)\n",
    "top_courses = courses[:20]  # Replace with FAISS output if needed\n",
    "\n",
    "# Run inference with improved prompt\n",
    "inference_results = perform_batch_inference(user_query, top_courses)\n",
    "\n",
    "# Print the final output\n",
    "print(json.dumps(inference_results, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Which course is suitable for beginners in Data Science?\n",
      "Number of Retrieved Courses: 10\n",
      "Prompt: \n",
      "You are an AI assistant helping to answer course-related questions.\n",
      "\n",
      "**Task:**  \n",
      "- Analyze the retrieved courses to answer the query.\n",
      "- Use context, reasoning, and comparison if needed.\n",
      "\n",
      "**Data Format:**  \n",
      "Each course has the following attributes:\n",
      "- \"course_id\": Unique ID for the course.\n",
      "- \"title\": Name of the course.\n",
      "- \"url\": Link to the course.\n",
      "- \"description\": Brief overview of the course.\n",
      "- \"category\": Main category of the course.\n",
      "- \"sub_category\": Subcategory if available.\n",
      "- \"course_info\": Language and subtitle information.\n",
      "- \"rating\": Overall user rating (out of 5).\n",
      "- \"reviews\": Total number of reviews and positive percentage.\n",
      "- \"knowledge_requirements\": What the course teaches and prerequisites.\n",
      "- \"learning_path\": Suitable learner level and career paths.\n",
      "- \"instructors\": List of instructor names.\n",
      "\n",
      "**User Query:**  \n",
      "Which course is suitable for beginners in Data Science?\n",
      "\n",
      "**Retrieved Courses:**  \n",
      "[\n",
      "  {\n",
      "    \"course_id\": \"C027a4aa3\",\n",
      "    \"title\": \"Best Data Science Course in India\",\n",
      "    \"url\": \"https://www.simplilearn.com/iitk-professional-certificate-course-data-science?tag=\",\n",
      "    \"description\": \"Stay ahead of the Data Science curve with this Best Data Science course in India. Master essential Data Science skills through applied learning with live classes by industry experts, asynchronous videos, hands-on labs, and masterclasses from distinguished IIT Kanpur faculty.\",\n",
      "    \"category\": \"nan\",\n",
      "    \"sub_category\": \"Unknown\",\n",
      "    \"course_info\": {\n",
      "      \"provider\": null,\n",
      "      \"type\": null,\n",
      "      \"language\": \"nan\",\n",
      "      \"subtitle_languages\": null\n",
      "    },\n",
      "    \"rating\": null,\n",
      "    \"positive_percentage\": null,\n",
      "    \"duration_months\": null,\n",
      "    \"reviews\": {\n",
      "      \"total_reviews\": 0,\n",
      "      \"positive_percentage\": null\n",
      "    },\n",
      "    \"knowledge_requirements\": {\n",
      "      \"teaches\": null,\n",
      "      \"prerequisites\": null\n",
      "    },\n",
      "    \"learning_path\": {\n",
      "      \"suitable_for\": [\n",
      "        \"Advanced Learners\"\n",
      "      ],\n",
      "      \"career_paths\": [\n",
      "        \"AI Engineer\"\n",
      "      ]\n",
      "    },\n",
      "    \"instructors\": null\n",
      "  },\n",
      "  {\n",
      "    \"course_id\": \"C34957d24\",\n",
      "    \"title\": \"Data Science as a Field\",\n",
      "    \"url\": \"https://www.coursera.org/learn/data-science-as-a-field?specialization=vital-skills-for-data-science\",\n",
      "    \"description\": \"This course provides a general introduction to the field of Data Science. It has been designed for aspiring data scientists, content experts who work with data scientists, or anyone interested in learning about what Data Science is and what it\\u2019s used for. Weekly topics include an overview of the skills needed to be a data scientist; the process and pitfalls involved in data science; and the practice of data science in the professional and academic world. This course is part of CU Boulder\\u2019s Master\\u2019s of Science in Data Science and was collaboratively designed by both academics and industry professionals to provide learners with an insider\\u2019s perspective on this exciting, evolving, and increasingly vital discipline.\",\n",
      "    \"category\": \"Data Science\",\n",
      "    \"sub_category\": \"Unknown\",\n",
      "    \"course_info\": {\n",
      "      \"provider\": null,\n",
      "      \"type\": null,\n",
      "      \"language\": \"English\",\n",
      "      \"subtitle_languages\": [\n",
      "        \"English\"\n",
      "      ]\n",
      "    },\n",
      "    \"rating\": 4.3,\n",
      "    \"positive_percentage\": 86.0,\n",
      "    \"duration_months\": 10.0,\n",
      "    \"reviews\": {\n",
      "      \"total_reviews\": 21,\n",
      "      \"positive_percentage\": 86.0\n",
      "    },\n",
      "    \"knowledge_requirements\": {\n",
      "      \"teaches\": [\n",
      "        \"Data Science,Applied Mathematics,Information Science,Statistics,Computer Science\"\n",
      "      ],\n",
      "      \"prerequisites\": [\n",
      "        \"Data Science,Applied Mathematics,Information Science,Statistics,Computer Science\"\n",
      "      ]\n",
      "    },\n",
      "    \"learning_path\": {\n",
      "      \"suitable_for\": [\n",
      "        \"Advanced Learners\"\n",
      "      ],\n",
      "      \"career_paths\": [\n",
      "        \"Data Scientist\"\n",
      "      ]\n",
      "    },\n",
      "    \"instructors\": [\n",
      "      \"Jane Wall\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"course_id\": \"C647f7997\",\n",
      "    \"title\": \"Data Science Specialization\",\n",
      "    \"url\": \"https://www.coursera.org/specializations/jhu-data-science\",\n",
      "    \"description\": \"Launch Your Career in Data Science. A ten-course introduction to data science, developed and taught by leading professors.\",\n",
      "    \"category\": \"Data Science\",\n",
      "    \"sub_category\": \"Unknown\",\n",
      "    \"course_info\": {\n",
      "      \"provider\": null,\n",
      "      \"type\": null,\n",
      "      \"language\": \"English\",\n",
      "      \"subtitle_languages\": [\n",
      "        \"English\",\n",
      "        \"Arabic\",\n",
      "        \"French\",\n",
      "        \"Portuguese (European)\",\n",
      "        \"Italian\",\n",
      "        \"Vietnamese\",\n",
      "        \"Korean\",\n",
      "        \"German\",\n",
      "        \"Russian\",\n",
      "        \"Spanish\",\n",
      "        \"Chinese (Simplified)\",\n",
      "        \"Portuguese (Brazilian)\",\n",
      "        \"Japanese\"\n",
      "      ]\n",
      "    },\n",
      "    \"rating\": 4.5,\n",
      "    \"positive_percentage\": 90.0,\n",
      "    \"duration_months\": 11.0,\n",
      "    \"reviews\": {\n",
      "      \"total_reviews\": 38510,\n",
      "      \"positive_percentage\": 90.0\n",
      "    },\n",
      "    \"knowledge_requirements\": {\n",
      "      \"teaches\": [\n",
      "        \"Github\",\n",
      "        \"Machine Learning\",\n",
      "        \"R Programming\",\n",
      "        \"Regression Analysis\",\n",
      "        \"Data Science\",\n",
      "        \"Rstudio\",\n",
      "        \"Data Analysis\",\n",
      "        \"Debugging\",\n",
      "        \"Data Manipulation\",\n",
      "        \"Regular Expression (REGEX)\",\n",
      "        \"Data Cleansing\",\n",
      "        \"Cluster Analysis\"\n",
      "      ],\n",
      "      \"prerequisites\": [\n",
      "        \"Github\",\n",
      "        \"Machine Learning\",\n",
      "        \"R Programming\"\n",
      "      ]\n",
      "    },\n",
      "    \"learning_path\": {\n",
      "      \"suitable_for\": [\n",
      "        \"Advanced Learners\"\n",
      "      ],\n",
      "      \"career_paths\": [\n",
      "        \"Data Scientist\"\n",
      "      ]\n",
      "    },\n",
      "    \"instructors\": [\n",
      "      \"Jeff Leek\",\n",
      "      \"PhD ,Roger D. Peng\",\n",
      "      \"PhD ,Brian Caffo\",\n",
      "      \"PhD\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"course_id\": \"Cadde243c\",\n",
      "    \"title\": \"Data Science Methodology\",\n",
      "    \"url\": \"https://www.coursera.org/learn/data-science-methodology\",\n",
      "    \"description\": \"If there is a shortcut to becoming a Data Scientist, then learning to think and work like a successful Data Scientist is it. Most of the established data scientists follow a similar methodology for solving Data Science problems.  In this course you will learn and then apply this methodology that can be used to tackle any Data Science scenario.  \",\n",
      "    \"category\": \"Data Science\",\n",
      "    \"sub_category\": \"Unknown\",\n",
      "    \"course_info\": {\n",
      "      \"provider\": null,\n",
      "      \"type\": null,\n",
      "      \"language\": \"English\",\n",
      "      \"subtitle_languages\": [\n",
      "        \"Arabic\",\n",
      "        \"French\",\n",
      "        \"Portuguese (European)\",\n",
      "        \"Italian\",\n",
      "        \"Vietnamese\",\n",
      "        \"German\",\n",
      "        \"Russian\",\n",
      "        \"Turkish\",\n",
      "        \"English\",\n",
      "        \"Spanish\",\n",
      "        \"Persian\"\n",
      "      ]\n",
      "    },\n",
      "    \"rating\": 4.6,\n",
      "    \"positive_percentage\": 92.0,\n",
      "    \"duration_months\": 8.0,\n",
      "    \"reviews\": {\n",
      "      \"total_reviews\": 18923,\n",
      "      \"positive_percentage\": 92.0\n",
      "    },\n",
      "    \"knowledge_requirements\": {\n",
      "      \"teaches\": [\n",
      "        \"Data Science,Methodology,CRISP-DM,Data Analysis,Data Mining\"\n",
      "      ],\n",
      "      \"prerequisites\": [\n",
      "        \"Data Science,Methodology,CRISP-DM,Data Analysis,Data Mining\"\n",
      "      ]\n",
      "    },\n",
      "    \"learning_path\": {\n",
      "      \"suitable_for\": [\n",
      "        \"Advanced Learners\"\n",
      "      ],\n",
      "      \"career_paths\": [\n",
      "        \"Data Scientist\"\n",
      "      ]\n",
      "    },\n",
      "    \"instructors\": [\n",
      "      \"Alex Aklson\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"course_id\": \"Cadde243c\",\n",
      "    \"title\": \"Data Science Methodology\",\n",
      "    \"url\": \"https://www.coursera.org/learn/data-science-methodology?specialization=introduction-data-science\",\n",
      "    \"description\": \"If there is a shortcut to becoming a Data Scientist, then learning to think and work like a successful Data Scientist is it. Most of the established data scientists follow a similar methodology for solving Data Science problems.  In this course you will learn and then apply this methodology that can be used to tackle any Data Science scenario.  \",\n",
      "    \"category\": \"Data Science\",\n",
      "    \"sub_category\": \"Unknown\",\n",
      "    \"course_info\": {\n",
      "      \"provider\": null,\n",
      "      \"type\": null,\n",
      "      \"language\": \"English\",\n",
      "      \"subtitle_languages\": [\n",
      "        \"Arabic\",\n",
      "        \"French\",\n",
      "        \"Portuguese (European)\",\n",
      "        \"Italian\",\n",
      "        \"Vietnamese\",\n",
      "        \"German\",\n",
      "        \"Russian\",\n",
      "        \"Turkish\",\n",
      "        \"English\",\n",
      "        \"Spanish\",\n",
      "        \"Persian\"\n",
      "      ]\n",
      "    },\n",
      "    \"rating\": 4.6,\n",
      "    \"positive_percentage\": 92.0,\n",
      "    \"duration_months\": 8.0,\n",
      "    \"reviews\": {\n",
      "      \"total_reviews\": 18923,\n",
      "      \"positive_percentage\": 92.0\n",
      "    },\n",
      "    \"knowledge_requirements\": {\n",
      "      \"teaches\": [\n",
      "        \"Data Science,Methodology,CRISP-DM,Data Analysis,Data Mining\"\n",
      "      ],\n",
      "      \"prerequisites\": [\n",
      "        \"Data Science,Methodology,CRISP-DM,Data Analysis,Data Mining\"\n",
      "      ]\n",
      "    },\n",
      "    \"learning_path\": {\n",
      "      \"suitable_for\": [\n",
      "        \"Advanced Learners\"\n",
      "      ],\n",
      "      \"career_paths\": [\n",
      "        \"Data Scientist\"\n",
      "      ]\n",
      "    },\n",
      "    \"instructors\": [\n",
      "      \"Alex Aklson\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"course_id\": \"C69d566ea\",\n",
      "    \"title\": \"Data Science Math Skills\",\n",
      "    \"url\": \"https://www.coursera.org/learn/datasciencemathskills\",\n",
      "    \"description\": \"Data science courses contain math\\u2014no avoiding that! This course is designed to teach learners the basic math you will need in order to be successful in almost any data science math course and was created for learners who have basic math skills but may not have taken algebra or pre-calculus. Data Science Math Skills introduces the core math that data science is built upon, with no extra complexity, introducing unfamiliar ideas and math symbols one-at-a-time. \",\n",
      "    \"category\": \"Math and Logic\",\n",
      "    \"sub_category\": \"Unknown\",\n",
      "    \"course_info\": {\n",
      "      \"provider\": null,\n",
      "      \"type\": null,\n",
      "      \"language\": \"English\",\n",
      "      \"subtitle_languages\": [\n",
      "        \"Arabic\",\n",
      "        \"French\",\n",
      "        \"Portuguese (European)\",\n",
      "        \"Italian\",\n",
      "        \"Vietnamese\",\n",
      "        \"Korean\",\n",
      "        \"German\",\n",
      "        \"Russian\",\n",
      "        \"English\",\n",
      "        \"Spanish\"\n",
      "      ]\n",
      "    },\n",
      "    \"rating\": 4.5,\n",
      "    \"positive_percentage\": 90.0,\n",
      "    \"duration_months\": 13.0,\n",
      "    \"reviews\": {\n",
      "      \"total_reviews\": 11112,\n",
      "      \"positive_percentage\": 90.0\n",
      "    },\n",
      "    \"knowledge_requirements\": {\n",
      "      \"teaches\": [\n",
      "        \"Bayes' Theorem,Bayesian Probability,Probability,Probability Theory\"\n",
      "      ],\n",
      "      \"prerequisites\": [\n",
      "        \"Bayes' Theorem,Bayesian Probability,Probability,Probability Theory\"\n",
      "      ]\n",
      "    },\n",
      "    \"learning_path\": {\n",
      "      \"suitable_for\": [\n",
      "        \"Advanced Learners\"\n",
      "      ],\n",
      "      \"career_paths\": [\n",
      "        \"AI Engineer\"\n",
      "      ]\n",
      "    },\n",
      "    \"instructors\": [\n",
      "      \"Daniel Egger\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"course_id\": \"C8a7a3f1b\",\n",
      "    \"title\": \"Data Scientist\",\n",
      "    \"url\": \"https://www.simplilearn.com/\",\n",
      "    \"description\": \"This IBM-sponsored Data Science course includes unique hackathons, masterclasses, webinars, and Ask-Me-Anything sessions. The online training will give you hands-on experience with R, Python, Machine Learning, Tableau, Hadoop, and Spark. Improve your knowledge with this Data Science course and live interaction with other practitioners and Machine Learning Engineers.\",\n",
      "    \"category\": \"nan\",\n",
      "    \"sub_category\": \"Unknown\",\n",
      "    \"course_info\": {\n",
      "      \"provider\": null,\n",
      "      \"type\": null,\n",
      "      \"language\": \"nan\",\n",
      "      \"subtitle_languages\": null\n",
      "    },\n",
      "    \"rating\": null,\n",
      "    \"positive_percentage\": null,\n",
      "    \"duration_months\": null,\n",
      "    \"reviews\": {\n",
      "      \"total_reviews\": 0,\n",
      "      \"positive_percentage\": null\n",
      "    },\n",
      "    \"knowledge_requirements\": {\n",
      "      \"teaches\": null,\n",
      "      \"prerequisites\": null\n",
      "    },\n",
      "    \"learning_path\": {\n",
      "      \"suitable_for\": [\n",
      "        \"Advanced Learners\"\n",
      "      ],\n",
      "      \"career_paths\": [\n",
      "        \"AI Engineer\"\n",
      "      ]\n",
      "    },\n",
      "    \"instructors\": null\n",
      "  },\n",
      "  {\n",
      "    \"course_id\": \"Cf8cc82eb\",\n",
      "    \"title\": \"Getting Started with Teaching Data Science in Schools\",\n",
      "    \"url\": \"https://www.futurelearn.com/courses/teaching-data-science\",\n",
      "    \"description\": \"Learn the basics of data science and how to introduce data science in the classroom.\",\n",
      "    \"category\": \"nan\",\n",
      "    \"sub_category\": \"Unknown\",\n",
      "    \"course_info\": {\n",
      "      \"provider\": null,\n",
      "      \"type\": null,\n",
      "      \"language\": \"nan\",\n",
      "      \"subtitle_languages\": null\n",
      "    },\n",
      "    \"rating\": null,\n",
      "    \"positive_percentage\": null,\n",
      "    \"duration_months\": 3.0,\n",
      "    \"reviews\": {\n",
      "      \"total_reviews\": 0,\n",
      "      \"positive_percentage\": null\n",
      "    },\n",
      "    \"knowledge_requirements\": {\n",
      "      \"teaches\": null,\n",
      "      \"prerequisites\": null\n",
      "    },\n",
      "    \"learning_path\": {\n",
      "      \"suitable_for\": [\n",
      "        \"Advanced Learners\"\n",
      "      ],\n",
      "      \"career_paths\": [\n",
      "        \"AI Engineer\"\n",
      "      ]\n",
      "    },\n",
      "    \"instructors\": null\n",
      "  },\n",
      "  {\n",
      "    \"course_id\": \"Cf8cc82eb\",\n",
      "    \"title\": \"Getting Started with Teaching Data Science in Schools\",\n",
      "    \"url\": \"https://www.futurelearn.com/courses/teaching-data-science\",\n",
      "    \"description\": \"Learn the basics of data science and how to introduce data science in the classroom.\",\n",
      "    \"category\": \"nan\",\n",
      "    \"sub_category\": \"Unknown\",\n",
      "    \"course_info\": {\n",
      "      \"provider\": null,\n",
      "      \"type\": null,\n",
      "      \"language\": \"nan\",\n",
      "      \"subtitle_languages\": null\n",
      "    },\n",
      "    \"rating\": null,\n",
      "    \"positive_percentage\": null,\n",
      "    \"duration_months\": 3.0,\n",
      "    \"reviews\": {\n",
      "      \"total_reviews\": 0,\n",
      "      \"positive_percentage\": null\n",
      "    },\n",
      "    \"knowledge_requirements\": {\n",
      "      \"teaches\": null,\n",
      "      \"prerequisites\": null\n",
      "    },\n",
      "    \"learning_path\": {\n",
      "      \"suitable_for\": [\n",
      "        \"Advanced Learners\"\n",
      "      ],\n",
      "      \"career_paths\": [\n",
      "        \"AI Engineer\"\n",
      "      ]\n",
      "    },\n",
      "    \"instructors\": null\n",
      "  },\n",
      "  {\n",
      "    \"course_id\": \"Ca68e750c\",\n",
      "    \"title\": \"Introduction to Data Science Specialization\",\n",
      "    \"url\": \"https://www.coursera.org/specializations/introduction-data-science\",\n",
      "    \"description\": \"Launch your career in data science. Gain foundational data science skills to prepare for a career or further advanced learning in data science. \",\n",
      "    \"category\": \"Data Science\",\n",
      "    \"sub_category\": \"Unknown\",\n",
      "    \"course_info\": {\n",
      "      \"provider\": null,\n",
      "      \"type\": null,\n",
      "      \"language\": \"English\",\n",
      "      \"subtitle_languages\": [\n",
      "        \"English\",\n",
      "        \"Arabic\",\n",
      "        \"French\",\n",
      "        \"Portuguese (European)\",\n",
      "        \"Italian\",\n",
      "        \"Vietnamese\",\n",
      "        \"German\",\n",
      "        \"Russian\",\n",
      "        \"Turkish\",\n",
      "        \"Spanish\",\n",
      "        \"Persian\"\n",
      "      ]\n",
      "    },\n",
      "    \"rating\": 4.7,\n",
      "    \"positive_percentage\": 94.0,\n",
      "    \"duration_months\": 5.0,\n",
      "    \"reviews\": {\n",
      "      \"total_reviews\": 11927,\n",
      "      \"positive_percentage\": 94.0\n",
      "    },\n",
      "    \"knowledge_requirements\": {\n",
      "      \"teaches\": [\n",
      "        \"Data Science\",\n",
      "        \"Relational Database Management System (RDBMS)\",\n",
      "        \"Cloud Databases\",\n",
      "        \"Python Programming\",\n",
      "        \"SQL\",\n",
      "        \"Deep Learning\",\n",
      "        \"Machine Learning\",\n",
      "        \"Big Data\",\n",
      "        \"Data Mining\",\n",
      "        \"Github\",\n",
      "        \"Jupyter notebooks\",\n",
      "        \"Rstudio\"\n",
      "      ],\n",
      "      \"prerequisites\": [\n",
      "        \"Data Science\",\n",
      "        \"Relational Database Management System (RDBMS)\",\n",
      "        \"Cloud Databases\"\n",
      "      ]\n",
      "    },\n",
      "    \"learning_path\": {\n",
      "      \"suitable_for\": [\n",
      "        \"Advanced Learners\"\n",
      "      ],\n",
      "      \"career_paths\": [\n",
      "        \"Data Scientist\"\n",
      "      ]\n",
      "    },\n",
      "    \"instructors\": [\n",
      "      \"Rav Ahuja ,Alex Aklson ,Aije Egwaikhide ,Svetlana Levitan ,Romeo Kienzler ,Polong Lin ,Hima Vasudevan\"\n",
      "    ]\n",
      "  }\n",
      "]\n",
      "\n",
      "**Instructions:**  \n",
      "- Analyze the courses to determine if they fully or partially answer the query.\n",
      "- For comparative questions (e.g., \"Which is better for beginners?\"), rank or explain.\n",
      "- For unavailable information, reply with the most appropriate courses to the query.\n",
      "\n",
      "**Output:**  \n",
      "Provide a brief reasoning and final suggestion or answer.\n",
      "Raw Response: model='qwen2.5:1.5b' created_at='2025-03-28T22:32:25.8143518Z' done=True done_reason='stop' total_duration=80124663700 load_duration=37002800 prompt_eval_count=2048 prompt_eval_duration=55921000000 eval_count=411 eval_duration=24164000000 response='To answer the question based on the course details provided:\\n\\n1. **Course 2** - \"Introduction to Data Science Specialization\" by Coursera offers foundational data science skills, which is suitable for beginners as it provides a comprehensive start with various tools.\\n   - This course appears more suitable for beginners compared to other specialized courses that require more advanced knowledge.\\n\\n2. **Course 1** - \"Getting Started with Teaching Data Science in Schools\" on FutureLearn introduces the basics of teaching data science but lacks specific skills and tools like Python, SQL, R programming which are essential.\\n   - This course is better suited for educators or those looking to teach rather than learners who need practical data science knowledge.\\n\\n3. **Course 4** - \"Introduction to Data Science Specialization\" by Coursera offers a more in-depth look into various aspects of data science.\\n   - While it has a higher rating and good positive percentage, it is recommended as a better choice for advanced learners since the specialized courses like this one provide deeper dives into specific skills.\\n\\n4. **Course 3** - \"Introduction to Data Science Specialization\" by Coursera offers foundational skills but doesn\\'t cover the detailed knowledge needed in data science.\\n   - This course ranks lower due to its lack of depth and practical application, which are important for advanced learners.\\n\\n5. **Other Courses**  \\n- Other courses offer a mix of theoretical and practical aspects but may not fully address all specific requirements or use cases for beginners and advanced learners respectively.\\n\\nFinal suggestion:\\nFor those looking to gain foundational data science skills suitable for beginners, I would recommend \"Introduction to Data Science Specialization\" by Coursera. It provides a comprehensive start with various tools and is generally easier for beginners to grasp compared to specialized courses that require more in-depth knowledge of specific areas like deep learning or machine learning.\\n\\nFor learners seeking deeper dives into data science skills, considering the \"Introduction to Data Science Specialization\" on Coursera would be beneficial, especially if they are interested in practical applications.' context=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 271, 2610, 525, 458, 15235, 17847, 10476, 311, 4226, 3308, 13904, 4755, 382, 334, 6262, 66963, 2303, 12, 37427, 2986, 279, 30403, 13980, 311, 4226, 279, 3239, 624, 12, 5443, 2266, 11, 32711, 11, 323, 12313, 421, 4362, 382, 334, 1043, 15042, 66963, 2303, 4854, 3308, 702, 279, 2701, 8201, 510, 12, 330, 11856, 842, 788, 28650, 3034, 369, 279, 3308, 624, 12, 330, 2102, 788, 3988, 315, 279, 3308, 624, 12, 330, 1085, 788, 5948, 311, 279, 3308, 624, 12, 330, 4684, 788, 36518, 23251, 315, 279, 3308, 624, 12, 330, 5471, 788, 4697, 5582, 315, 279, 3308, 624, 12, 330, 1966, 11847, 788, 3719, 5471, 421, 2500, 624, 12, 330, 11856, 3109, 788, 11434, 323, 31735, 1995, 624, 12, 330, 21931, 788, 27893, 1196, 10728, 320, 411, 315, 220, 20, 4292, 12, 330, 39475, 788, 10657, 1372, 315, 8379, 323, 6785, 11414, 624, 12, 330, 89053, 89632, 788, 3555, 279, 3308, 32892, 323, 85258, 624, 12, 330, 20981, 2638, 788, 85246, 62960, 2188, 323, 6931, 12716, 624, 12, 330, 258, 91366, 788, 1759, 315, 32215, 5036, 382, 334, 1474, 11361, 66963, 2303, 23085, 3308, 374, 14452, 369, 46850, 304, 2885, 9965, 1939, 334, 12020, 82612, 47678, 66963, 2303, 9640, 220, 341, 262, 330, 11856, 842, 788, 330, 34, 15, 17, 22, 64, 19, 5305, 18, 756, 262, 330, 2102, 788, 330, 14470, 2885, 9965, 16615, 304, 6747, 756, 262, 330, 1085, 788, 330, 2428, 1110, 2136, 514, 6383, 457, 1885, 905, 16438, 275, 74, 92308, 15774, 1786, 20962, 68429, 13945, 30319, 1835, 30, 4578, 428, 345, 262, 330, 4684, 788, 330, 38102, 8305, 315, 279, 2885, 9965, 15655, 448, 419, 7107, 2885, 9965, 3308, 304, 6747, 13, 10824, 7565, 2885, 9965, 7361, 1526, 9251, 6832, 448, 3887, 6846, 553, 4958, 11647, 11, 39007, 6803, 11, 6078, 10326, 49948, 11, 323, 7341, 8855, 504, 38475, 358, 952, 30563, 24998, 21564, 10346, 262, 330, 5471, 788, 330, 18759, 756, 262, 330, 1966, 11847, 788, 330, 13790, 756, 262, 330, 11856, 3109, 788, 341, 414, 330, 19979, 788, 845, 345, 414, 330, 1313, 788, 845, 345, 414, 330, 11528, 788, 330, 18759, 756, 414, 330, 40417, 77576, 788, 845, 198, 262, 1153, 262, 330, 21931, 788, 845, 345, 262, 330, 30487, 46044, 788, 845, 345, 262, 330, 17021, 88462, 788, 845, 345, 262, 330, 39475, 788, 341, 414, 330, 5035, 68706, 788, 220, 15, 345, 414, 330, 30487, 46044, 788, 845, 198, 262, 1153, 262, 330, 89053, 89632, 788, 341, 414, 330, 665, 14242, 788, 845, 345, 414, 330, 649, 82301, 788, 845, 198, 262, 1153, 262, 330, 20981, 2638, 788, 341, 414, 330, 72040, 480, 5478, 788, 2278, 286, 330, 35457, 59978, 4972, 698, 414, 3211, 414, 330, 94537, 24152, 788, 2278, 286, 330, 15469, 28383, 698, 414, 5133, 262, 1153, 262, 330, 258, 91366, 788, 845, 198, 220, 1153, 220, 341, 262, 330, 11856, 842, 788, 330, 34, 18, 19, 24, 20, 22, 67, 17, 19, 756, 262, 330, 2102, 788, 330, 1043, 9965, 438, 264, 8601, 756, 262, 330, 1085, 788, 330, 2428, 1110, 2136, 520, 413, 799, 64, 2659, 14, 12675, 13167, 30319, 1835, 32434, 7409, 19130, 30, 15144, 2022, 39254, 2174, 45307, 3305, 15193, 13945, 30319, 1835, 756, 262, 330, 4684, 788, 330, 1986, 3308, 5707, 264, 4586, 16800, 311, 279, 2070, 315, 2885, 9965, 13, 1084, 702, 1012, 6188, 369, 59113, 821, 13923, 11, 2213, 11647, 879, 975, 448, 821, 13923, 11, 476, 5489, 8014, 304, 6832, 911, 1128, 2885, 9965, 374, 323, 1128, 432, 3770, 17, 15, 16, 24, 82, 1483, 369, 13, 33014, 13347, 2924, 458, 23251, 315, 279, 7361, 4362, 311, 387, 264, 821, 27468, 26, 279, 1882, 323, 80975, 6398, 304, 821, 8038, 26, 323, 279, 6588, 315, 821, 8038, 304, 279, 6584, 323, 14250, 1879, 13, 1096, 3308, 374, 949, 315, 40743, 55643, 3770, 17, 15, 16, 24, 82, 10824, 3770, 17, 15, 16, 24, 82, 315, 9965, 304, 2885, 9965, 323, 572, 11182, 7887, 6188, 553, 2176, 47609, 323, 4958, 15387, 311, 3410, 52143, 448, 458, 54365, 3770, 17, 15, 16, 24, 82, 13057, 389, 419, 13245, 11, 40928, 11, 323, 14756, 16198, 25364, 10346, 262, 330, 5471, 788, 330, 1043, 9965, 756, 262, 330, 1966, 11847, 788, 330, 13790, 756, 262, 330, 11856, 3109, 788, 341, 414, 330, 19979, 788, 845, 345, 414, 330, 1313, 788, 845, 345, 414, 330, 11528, 788, 330, 22574, 756, 414, 330, 40417, 77576, 788, 2278, 286, 330, 22574, 698, 414, 5133, 262, 1153, 262, 330, 21931, 788, 220, 19, 13, 18, 345, 262, 330, 30487, 46044, 788, 220, 23, 21, 13, 15, 345, 262, 330, 17021, 88462, 788, 220, 16, 15, 13, 15, 345, 262, 330, 39475, 788, 341, 414, 330, 5035, 68706, 788, 220, 17, 16, 345, 414, 330, 30487, 46044, 788, 220, 23, 21, 13, 15, 198, 262, 1153, 262, 330, 89053, 89632, 788, 341, 414, 330, 665, 14242, 788, 2278, 286, 330, 1043, 9965, 11, 75856, 49795, 11, 14873, 9965, 11, 38599, 11, 37332, 9965, 698, 414, 3211, 414, 330, 649, 82301, 788, 2278, 286, 330, 1043, 9965, 11, 75856, 49795, 11, 14873, 9965, 11, 38599, 11, 37332, 9965, 698, 414, 5133, 262, 1153, 262, 330, 20981, 2638, 788, 341, 414, 330, 72040, 480, 5478, 788, 2278, 286, 330, 35457, 59978, 4972, 698, 414, 3211, 414, 330, 94537, 24152, 788, 2278, 286, 330, 1043, 67309, 698, 414, 5133, 262, 1153, 262, 330, 258, 91366, 788, 2278, 414, 330, 62502, 9736, 698, 262, 5133, 220, 1153, 220, 341, 262, 330, 11856, 842, 788, 330, 34, 21, 19, 22, 69, 22, 24, 24, 22, 756, 262, 330, 2102, 788, 330, 1043, 9965, 9785, 2022, 756, 262, 330, 1085, 788, 330, 2428, 1110, 2136, 520, 413, 799, 64, 2659, 2687, 2964, 8040, 4437, 16739, 13945, 30319, 1835, 756, 262, 330, 4684, 788, 330, 32067, 4615, 40476, 304, 2885, 9965, 13, 362, 5779, 68429, 16800, 311, 821, 8038, 11, 7881, 323, 15599, 553, 6388, 44624, 10346, 262, 330, 5471, 788, 330, 1043, 9965, 756, 262, 330, 1966, 11847, 788, 330, 13790, 756, 262, 330, 11856, 3109, 788, 341, 414, 330, 19979, 788, 845, 345, 414, 330, 1313, 788, 845, 345, 414, 330, 11528, 788, 330, 22574, 756, 414, 330, 40417, 77576, 788, 2278, 286, 330, 22574, 756, 286, 330, 6953, 68291, 756, 286, 330, 43197, 756, 286, 330, 7084, 768, 35454, 320, 63369, 15752, 286, 330, 69111, 756, 286, 330, 94054, 43419, 756, 286, 330, 42, 45195, 756, 286, 330, 32079, 756, 286, 330, 47707, 756, 286, 330, 61797, 756, 286, 330, 44923, 320, 50, 73837, 15752, 286, 330, 7084, 768, 35454, 320, 67199, 1103, 15752, 286, 330, 51466, 698, 414, 5133, 262, 1153, 262, 330, 21931, 788, 220, 19, 13, 20, 345, 262, 330, 30487, 46044, 788, 220, 24, 15, 13, 15, 345, 262, 330, 17021, 88462, 788, 220, 16, 16, 13, 15, 345, 262, 330, 39475, 788, 341, 414, 330, 5035, 68706, 788, 220, 18, 23, 20, 16, 15, 345, 414, 330, 30487, 46044, 788, 220, 24, 15, 13, 15, 198, 262, 1153, 262, 330, 89053, 89632, 788, 341, 414, 330, 665, 14242, 788, 2278, 286, 330, 78717, 756, 286, 330, 21605, 20909, 756, 286, 330, 49, 38424, 756, 286, 330, 45200, 18320, 756, 286, 330, 1043, 9965, 756, 286, 330, 49, 59019, 756, 286, 330, 1043, 18320, 756, 286, 330, 7939, 3173, 756, 286, 330, 1043, 60911, 2914, 756, 286, 330, 30404, 16378, 320, 12173, 3257, 15752, 286, 330, 1043, 85662, 287, 756, 286, 330, 28678, 18320, 698, 414, 3211, 414, 330, 649, 82301, 788, 2278, 286, 330, 78717, 756, 286, 330, 21605, 20909, 756, 286, 330, 49, 38424, 698, 414, 5133, 262, 1153, 262, 330, 20981, 2638, 788, 341, 414, 330, 72040, 480, 5478, 788, 2278, 286, 330, 35457, 59978, 4972, 698, 414, 3211, 414, 330, 94537, 24152, 788, 2278, 286, 330, 1043, 67309, 698, 414, 5133, 262, 1153, 262, 330, 258, 91366, 788, 2278, 414, 330, 38627, 1967, 1225, 756, 414, 330, 3357, 35, 1154, 78425, 422, 13, 51050, 756, 414, 330, 3357, 35, 1154, 50088, 356, 2649, 78, 756, 414, 330, 3357, 35, 698, 262, 5133, 220, 1153, 220, 341, 262, 330, 11856, 842, 788, 330, 93338, 450, 17, 19, 18, 66, 756, 262, 330, 2102, 788, 330, 1043, 9965, 6730, 2449, 756, 262, 330, 1085, 788, 330, 2428, 1110, 2136, 520, 413, 799, 64, 2659, 14, 12675, 13167, 30319, 1835, 50297, 2449, 756, 262, 330, 4684, 788, 330, 2679, 1052, 374, 264, 37115, 311, 10454, 264, 2885, 67309, 11, 1221, 6832, 311, 1744, 323, 975, 1075, 264, 6849, 2885, 67309, 374, 432, 13, 7496, 315, 279, 9555, 821, 13923, 1795, 264, 4428, 37052, 369, 21828, 2885, 9965, 5322, 13, 220, 758, 419, 3308, 498, 686, 3960, 323, 1221, 3796, 419, 37052, 429, 646, 387, 1483, 311, 21403, 894, 2885, 9965, 15048, 13, 220, 21796, 262, 330, 5471, 788, 330, 1043, 9965, 756, 262, 330, 1966, 11847, 788, 330, 13790, 756, 262, 330, 11856, 3109, 788, 341, 414, 330, 19979, 788, 845, 345, 414, 330, 1313, 788, 845, 345, 414, 330, 11528, 788, 330, 22574, 756, 414, 330, 40417, 77576, 788, 2278, 286, 330, 6953, 68291, 756, 286, 330, 43197, 756, 286, 330, 7084, 768, 35454, 320, 63369, 15752, 286, 330, 69111, 756, 286, 330, 94054, 43419, 756, 286, 330, 32079, 756, 286, 330, 47707, 756, 286, 330, 36962, 73620, 756, 286, 330, 22574, 756, 286, 330, 61797, 756, 286, 330, 58642, 1103, 698, 414, 5133, 262, 1153, 262, 330, 21931, 788, 220, 19, 13, 21, 345, 262, 330, 30487, 46044, 788, 220, 24, 17, 13, 15, 345, 262, 330, 17021, 88462, 788, 220, 23, 13, 15, 345, 262, 330, 39475, 788, 341, 414, 330, 5035, 68706, 788, 220, 16, 23, 24, 17, 18, 345, 414, 330, 30487, 46044, 788, 220, 24, 17, 13, 15, 198, 262, 1153, 262, 330, 89053, 89632, 788, 341, 414, 330, 665, 14242, 788, 2278, 286, 330, 1043, 9965, 11, 3523, 2449, 11, 8973, 55506, 12, 8395, 11, 1043, 18320, 11, 1043, 25832, 698, 414, 3211, 414, 330, 649, 82301, 788, 2278, 286, 330, 1043, 9965, 11, 3523, 2449, 11, 8973, 55506, 12, 8395, 11, 1043, 18320, 11, 1043, 25832, 698, 414, 5133, 262, 1153, 262, 330, 20981, 2638, 788, 341, 414, 330, 72040, 480, 5478, 788, 2278, 286, 330, 35457, 59978, 4972, 698, 414, 3211, 414, 330, 94537, 24152, 788, 2278, 286, 330, 1043, 67309, 698, 414, 5133, 262, 1153, 262, 330, 258, 91366, 788, 2278, 414, 330, 27387, 362, 10561, 930, 698, 262, 5133, 220, 1153, 220, 341, 262, 330, 11856, 842, 788, 330, 93338, 450, 17, 19, 18, 66, 756, 262, 330, 2102, 788, 330, 1043, 9965, 6730, 2449, 756, 262, 330, 1085, 788, 330, 2428, 1110, 2136, 520, 413, 799, 64, 2659, 14, 12675, 13167, 30319, 1835, 50297, 2449, 30, 15144, 2022, 16563, 16741, 13945, 30319, 1835, 756, 262, 330, 4684, 788, 330, 2679, 1052, 374, 264, 37115, 311, 10454, 264, 2885, 67309, 11, 1221, 6832, 311, 1744, 323, 975, 1075, 264, 6849, 2885, 67309, 374, 432, 13, 7496, 315, 279, 9555, 821, 13923, 1795, 264, 4428, 37052, 369, 21828, 2885, 9965, 5322, 13, 220, 758, 419, 3308, 498, 686, 3960, 323, 1221, 3796, 419, 37052, 429, 646, 387, 1483, 311, 21403, 894, 2885, 9965, 15048, 13, 220, 21796, 262, 330, 5471, 788, 330, 1043, 9965, 756, 262, 330, 1966, 11847, 788, 330, 13790, 756, 262, 330, 11856, 3109, 788, 341, 414, 330, 19979, 788, 845, 345, 414, 330, 1313, 788, 845, 345, 414, 330, 11528, 788, 330, 22574, 756, 414, 330, 40417, 77576, 788, 2278, 286, 330, 6953, 68291, 756, 286, 330, 43197, 756, 286, 330, 7084, 768, 35454, 320, 63369, 15752, 286, 330, 69111, 756, 286, 330, 94054, 43419, 756, 286, 330, 32079, 756, 286, 330, 47707, 756, 286, 330, 36962, 73620, 756, 286, 330, 22574, 756, 286, 330, 61797, 756, 286, 330, 58642, 1103, 698, 414, 5133, 262, 1153, 262, 330, 21931, 788, 220, 19, 13, 21, 345, 262, 330, 30487, 46044, 788, 220, 24, 17, 13, 15, 345, 262, 330, 17021, 88462, 788, 220, 23, 13, 15, 345, 262, 330, 39475, 788, 341, 414, 330, 5035, 68706, 788, 220, 16, 23, 24, 17, 18, 345, 414, 330, 30487, 46044, 788, 220, 24, 17, 13, 15, 198, 262, 1153, 262, 330, 89053, 89632, 788, 341, 414, 330, 665, 14242, 788, 2278, 286, 330, 1043, 9965, 11, 3523, 2449, 11, 8973, 55506, 12, 8395, 11, 1043, 18320, 11, 1043, 25832, 698, 414, 3211, 414, 330, 649, 82301, 788, 2278, 286, 330, 1043, 9965, 11, 3523, 2449, 11, 8973, 55506, 12, 8395, 11, 1043, 18320, 11, 1043, 25832, 698, 414, 5133, 262, 1153, 262, 330, 20981, 2638, 788, 341, 414, 330, 72040, 480, 5478, 788, 2278, 286, 330, 35457, 59978, 4972, 698, 414, 3211, 414, 330, 94537, 24152, 788, 2278, 286, 330, 1043, 67309, 698, 414, 5133, 262, 1153, 262, 330, 258, 91366, 788, 2278, 414, 330, 27387, 362, 10561, 930, 698, 262, 5133, 220, 1153, 220, 341, 262, 330, 11856, 842, 788, 330, 34, 21, 24, 67, 20, 21, 21, 12508, 756, 262, 330, 2102, 788, 330, 1043, 9965, 4149, 30240, 756, 262, 330, 1085, 788, 330, 2428, 1110, 2136, 520, 413, 799, 64, 2659, 14, 12675, 37566, 5061, 72, 954, 336, 587, 53240, 756, 262, 330, 4684, 788, 330, 1043, 8038, 13980, 6644, 6888, 3770, 17, 15, 16, 19, 2152, 30426, 429, 0, 1096, 3308, 374, 6188, 311, 4538, 52143, 279, 6770, 6888, 498, 686, 1184, 304, 1973, 311, 387, 6849, 304, 4558, 894, 821, 8038, 6888, 3308, 323, 572, 3465, 369, 52143, 879, 614, 6770, 6888, 7361, 714, 1231, 537, 614, 4429, 46876, 476, 855, 48136, 41349, 13, 2885, 9965, 4149, 30240, 38919, 279, 6200, 6888, 429, 821, 8038, 374, 5798, 5193, 11, 448, 902, 4960, 23094, 11, 31918, 49283, 6708, 323, 6888, 17738, 825, 28783, 7409, 7246, 13, 21796, 262, 330, 5471, 788, 330, 8815, 323, 36101, 756, 262, 330, 1966, 11847, 788, 330, 13790, 756, 262, 330, 11856, 3109, 788, 341, 414, 330, 19979, 788, 845, 345, 414, 330, 1313, 788, 845, 345, 414, 330, 11528, 788, 330, 22574, 756, 414, 330, 40417, 77576, 788, 2278, 286, 330, 6953, 68291, 756, 286, 330, 43197, 756, 286, 330, 7084, 768, 35454, 320, 63369, 15752, 286, 330, 69111, 756, 286, 330, 94054, 43419, 756, 286, 330, 42, 45195, 756, 286, 330, 32079, 756, 286, 330, 47707, 756, 286, 330, 22574, 756, 286, 330, 61797, 698, 414, 5133, 262, 1153, 262, 330, 21931, 788, 220, 19, 13, 20, 345, 262, 330, 30487, 46044, 788, 220, 24, 15, 13, 15, 345, 262, 330, 17021, 88462, 788, 220, 16, 18, 13, 15, 345, 262, 330, 39475, 788, 341, 414, 330, 5035, 68706, 788, 220, 16, 16, 16, 16, 17, 345, 414, 330, 30487, 46044, 788, 220, 24, 15, 13, 15, 198, 262, 1153, 262, 330, 89053, 89632, 788, 341, 414, 330, 665, 14242, 788, 2278, 286, 330, 22587, 288, 6, 576, 13173, 8161, 352, 29221, 86639, 11, 88464, 11, 88464, 30435, 698, 414, 3211, 414, 330, 649, 82301, 788, 2278, 286, 330, 22587, 288, 6, 576, 13173, 8161, 352, 29221, 86639, 11, 88464, 11, 88464, 30435, 698, 414, 5133, 262, 1153, 262, 330, 20981, 2638, 788, 341, 414, 330, 72040, 480, 5478, 788, 2278, 286, 330, 35457, 59978, 4972, 698, 414, 3211, 414, 330, 94537, 24152, 788, 2278, 286, 330, 15469, 28383, 698, 414, 5133, 262, 1153, 262, 330, 258, 91366, 788, 2278, 414, 330, 40586, 38075, 1389, 698, 262, 5133, 220, 1153, 220, 341, 262, 330, 11856, 842, 788, 330, 34, 23, 64, 22, 64, 18, 69, 16, 65, 756, 262, 330, 2102, 788, 330, 1043, 67309, 756, 262, 330, 1085, 788, 330, 2428, 1110, 2136, 514, 6383, 457, 1885, 905, 35075, 262, 330, 4684, 788, 330, 1986, 27922, 63550, 2885, 9965, 3308, 5646, 4911, 17086, 587, 2382, 11, 7341, 8855, 11, 3482, 46337, 11, 323, 20437, 5251, 68, 12, 77303, 15704, 13, 576, 2860, 4862, 686, 2968, 498, 6078, 10326, 3139, 448, 431, 11, 13027, 11, 12960, 20909, 11, 6633, 2863, 11, 472, 25268, 11, 323, 26467, 13, 64084, 697, 6540, 448, 419, 2885, 9965, 3308, 323, 3887, 16230, 448, 1008, 42095, 323, 12960, 20909, 48696, 10346, 262, 330, 5471, 788, 330, 18759, 756, 262, 330, 1966, 11847, 788, 330, 13790, 756, 262, 330, 11856, 3109, 788, 341, 414, 330, 19979, 788, 845, 345, 414, 330, 1313, 788, 845, 345, 414, 330, 11528, 788, 330, 18759, 756, 414, 330, 40417, 77576, 788, 845, 198, 262, 1153, 262, 330, 21931, 788, 845, 345, 262, 330, 30487, 46044, 788, 845, 345, 262, 330, 17021, 88462, 788, 845, 345, 262, 330, 39475, 788, 341, 414, 330, 5035, 68706, 788, 220, 15, 345, 414, 330, 30487, 46044, 788, 845, 198, 262, 1153, 262, 330, 89053, 89632, 788, 341, 414, 330, 665, 14242, 788, 845, 345, 414, 330, 649, 82301, 788, 845, 198, 262, 1153, 262, 330, 20981, 2638, 788, 341, 414, 330, 72040, 480, 5478, 788, 2278, 286, 330, 35457, 59978, 4972, 698, 414, 3211, 414, 330, 94537, 24152, 788, 2278, 286, 330, 15469, 28383, 698, 414, 5133, 262, 1153, 262, 330, 258, 91366, 788, 845, 198, 220, 1153, 220, 341, 262, 330, 11856, 842, 788, 330, 34, 69, 23, 638, 23, 17, 3065, 756, 262, 330, 2102, 788, 330, 28655, 35812, 448, 44277, 2885, 9965, 304, 30383, 756, 262, 330, 1085, 788, 330, 2428, 1110, 2136, 97693, 12675, 905, 2899, 16349, 14, 665, 11829, 13945, 30319, 1835, 756, 262, 330, 4684, 788, 330, 23824, 279, 31774, 315, 821, 8038, 323, 1246, 311, 19131, 821, 8038, 304, 279, 24017, 10346, 262, 330, 5471, 788, 330, 18759, 756, 262, 330, 1966, 11847, 788, 330, 13790, 756, 262, 330, 11856, 3109, 788, 341, 414, 330, 19979, 788, 845, 345, 414, 330, 1313, 788, 845, 345, 414, 330, 11528, 788, 330, 18759, 756, 414, 330, 40417, 77576, 788, 845, 198, 262, 1153, 262, 330, 21931, 788, 845, 345, 262, 330, 30487, 46044, 788, 845, 345, 262, 330, 17021, 88462, 788, 220, 18, 13, 15, 345, 262, 330, 39475, 788, 341, 414, 330, 5035, 68706, 788, 220, 15, 345, 414, 330, 30487, 46044, 788, 845, 198, 262, 1153, 262, 330, 89053, 89632, 788, 341, 414, 330, 665, 14242, 788, 845, 345, 414, 330, 649, 82301, 788, 845, 198, 262, 1153, 262, 330, 20981, 2638, 788, 341, 414, 330, 72040, 480, 5478, 788, 2278, 286, 330, 35457, 59978, 4972, 698, 414, 3211, 414, 330, 94537, 24152, 788, 2278, 286, 330, 15469, 28383, 698, 414, 5133, 262, 1153, 262, 330, 258, 91366, 788, 845, 198, 220, 1153, 220, 341, 262, 330, 11856, 842, 788, 330, 34, 69, 23, 638, 23, 17, 3065, 756, 262, 330, 2102, 788, 330, 28655, 35812, 448, 44277, 2885, 9965, 304, 30383, 756, 262, 330, 1085, 788, 330, 2428, 1110, 2136, 97693, 12675, 905, 2899, 16349, 14, 665, 11829, 13945, 30319, 1835, 756, 262, 330, 4684, 788, 330, 23824, 279, 31774, 315, 821, 8038, 323, 1246, 311, 19131, 821, 8038, 304, 279, 24017, 10346, 262, 330, 5471, 788, 330, 18759, 756, 262, 330, 1966, 11847, 788, 330, 13790, 756, 262, 330, 11856, 3109, 788, 341, 414, 330, 19979, 788, 845, 345, 414, 330, 1313, 788, 845, 345, 414, 330, 11528, 788, 330, 18759, 756, 414, 330, 40417, 77576, 788, 845, 198, 262, 1153, 262, 330, 21931, 788, 845, 345, 262, 330, 30487, 46044, 788, 845, 345, 262, 330, 17021, 88462, 788, 220, 18, 13, 15, 345, 262, 330, 39475, 788, 341, 414, 330, 5035, 68706, 788, 220, 15, 345, 414, 330, 30487, 46044, 788, 845, 198, 262, 1153, 262, 330, 89053, 89632, 788, 341, 414, 330, 665, 14242, 788, 845, 345, 414, 330, 649, 82301, 788, 845, 198, 262, 1153, 262, 330, 20981, 2638, 788, 341, 414, 330, 72040, 480, 5478, 788, 2278, 286, 330, 35457, 59978, 4972, 698, 414, 3211, 414, 330, 94537, 24152, 788, 2278, 286, 330, 15469, 28383, 698, 414, 5133, 262, 1153, 262, 330, 258, 91366, 788, 845, 198, 220, 1153, 220, 341, 262, 330, 11856, 842, 788, 330, 22571, 21, 23, 68, 22, 20, 15, 66, 756, 262, 330, 2102, 788, 330, 37155, 311, 2885, 9965, 9785, 2022, 756, 262, 330, 1085, 788, 330, 2428, 1110, 2136, 520, 413, 799, 64, 2659, 2687, 2964, 8040, 31114, 16741, 13945, 30319, 1835, 756, 262, 330, 4684, 788, 330, 32067, 697, 6931, 304, 821, 8038, 13, 49709, 88228, 821, 8038, 7361, 311, 10549, 369, 264, 6931, 476, 4623, 10847, 6832, 304, 821, 8038, 13, 21796, 262, 330, 5471, 788, 330, 1043, 9965, 756, 262, 330, 1966, 11847, 788, 330, 13790, 756, 262, 330, 11856, 3109, 788, 341, 414, 330, 19979, 788, 845, 345, 414, 330, 1313, 788, 845, 345, 414, 330, 11528, 788, 330, 22574, 756, 414, 330, 40417, 77576, 788, 2278, 286, 330, 22574, 756, 286, 330, 6953, 68291, 756, 286, 330, 43197, 756, 286, 330, 7084, 768, 35454, 320, 63369, 15752, 286, 330, 69111, 756, 286, 330, 94054, 43419, 756, 286, 330, 32079, 756, 286, 330, 47707, 756, 286, 330, 36962, 73620, 756, 286, 330, 61797, 756, 286, 330, 58642, 1103, 698, 414, 5133, 262, 1153, 262, 330, 21931, 788, 220, 19, 13, 22, 345, 262, 330, 30487, 46044, 788, 220, 24, 19, 13, 15, 345, 262, 330, 17021, 88462, 788, 220, 20, 13, 15, 345, 262, 330, 39475, 788, 341, 414, 330, 5035, 68706, 788, 220, 16, 16, 24, 17, 22, 345, 414, 330, 30487, 46044, 788, 220, 24, 19, 13, 15, 198, 262, 1153, 262, 330, 89053, 89632, 788, 341, 414, 330, 665, 14242, 788, 2278, 286, 330, 1043, 9965, 756, 286, 330, 6740, 1663, 9994, 9551, 739, 320, 49, 3506, 4826, 15752, 286, 330, 16055, 422, 23822, 756, 286, 330, 30280, 38424, 756, 286, 330, 6688, 756, 286, 330, 33464, 20909, 756, 286, 330, 21605, 20909, 756, 286, 330, 15636, 2885, 756, 286, 330, 1043, 25832, 756, 286, 330, 78717, 756, 286, 330, 41, 72852, 78531, 756, 286, 330, 49, 59019, 698, 414, 3211, 414, 330, 649, 82301, 788, 2278, 286, 330, 1043, 9965, 756, 286, 330, 6740, 1663, 9994, 9551, 739, 320, 49, 3506, 4826, 15752, 286, 330, 16055, 422, 23822, 698, 414, 5133, 262, 1153, 262, 330, 20981, 2638, 788, 341, 414, 330, 72040, 480, 5478, 788, 2278, 286, 330, 35457, 59978, 4972, 698, 414, 3211, 414, 330, 94537, 24152, 788, 2278, 286, 330, 1043, 67309, 698, 414, 5133, 262, 1153, 262, 330, 258, 91366, 788, 2278, 414, 330, 49, 402, 16366, 88708, 1154, 27387, 362, 10561, 930, 1154, 32, 31276, 38075, 9991, 1579, 8559, 1154, 50, 17115, 75, 3362, 27022, 12849, 1154, 49, 635, 78, 730, 3591, 89, 1536, 1154, 14658, 644, 8564, 1154, 39, 7523, 52834, 793, 15649, 698, 262, 5133, 220, 456, 2533, 334, 55291, 66963, 2303, 12, 37427, 2986, 279, 13980, 311, 8253, 421, 807, 7225, 476, 25244, 4226, 279, 3239, 624, 12, 1752, 54294, 4755, 320, 68, 1302, 2572, 330, 23085, 374, 2664, 369, 46850, 30, 3975, 7077, 476, 10339, 624, 12, 1752, 34987, 1995, 11, 9851, 448, 279, 1429, 8311, 13980, 311, 279, 3239, 382, 334, 5097, 66963, 2303, 60424, 264, 9814, 32711, 323, 1590, 23776, 476, 4226, 13, 151645, 198, 151644, 77091, 198, 1249, 4226, 279, 3405, 3118, 389, 279, 3308, 3565, 3897, 1447, 16, 13, 3070, 23340, 220, 17, 334, 481, 330, 37155, 311, 2885, 9965, 9785, 2022, 1, 553, 6244, 799, 64, 6081, 88228, 821, 8038, 7361, 11, 892, 374, 14452, 369, 46850, 438, 432, 5707, 264, 15817, 1191, 448, 5257, 7375, 624, 256, 481, 1096, 3308, 7952, 803, 14452, 369, 46850, 7707, 311, 1008, 27076, 13980, 429, 1373, 803, 10847, 6540, 382, 17, 13, 3070, 23340, 220, 16, 334, 481, 330, 28655, 35812, 448, 44277, 2885, 9965, 304, 30383, 1, 389, 12498, 23824, 38919, 279, 31774, 315, 12629, 821, 8038, 714, 36756, 3151, 7361, 323, 7375, 1075, 13027, 11, 7870, 11, 431, 15473, 892, 525, 7565, 624, 256, 481, 1096, 3308, 374, 2664, 31499, 369, 49694, 476, 1846, 3330, 311, 4538, 4751, 1091, 52143, 879, 1184, 14976, 821, 8038, 6540, 382, 18, 13, 3070, 23340, 220, 19, 334, 481, 330, 37155, 311, 2885, 9965, 9785, 2022, 1, 553, 6244, 799, 64, 6081, 264, 803, 304, 30310, 1401, 1119, 5257, 13566, 315, 821, 8038, 624, 256, 481, 5976, 432, 702, 264, 5080, 10728, 323, 1661, 6785, 11414, 11, 432, 374, 11102, 438, 264, 2664, 5754, 369, 10847, 52143, 2474, 279, 27076, 13980, 1075, 419, 825, 3410, 19117, 93421, 1119, 3151, 7361, 382, 19, 13, 3070, 23340, 220, 18, 334, 481, 330, 37155, 311, 2885, 9965, 9785, 2022, 1, 553, 6244, 799, 64, 6081, 88228, 7361, 714, 3171, 944, 3421, 279, 11682, 6540, 4362, 304, 821, 8038, 624, 256, 481, 1096, 3308, 20803, 4722, 4152, 311, 1181, 6853, 315, 7990, 323, 14976, 3766, 11, 892, 525, 2989, 369, 10847, 52143, 382, 20, 13, 3070, 11409, 47678, 334, 2303, 12, 6944, 13980, 3010, 264, 6514, 315, 31787, 323, 14976, 13566, 714, 1231, 537, 7225, 2621, 678, 3151, 8502, 476, 990, 5048, 369, 46850, 323, 10847, 52143, 15576, 382, 19357, 23776, 510, 2461, 1846, 3330, 311, 8722, 88228, 821, 8038, 7361, 14452, 369, 46850, 11, 358, 1035, 6934, 330, 37155, 311, 2885, 9965, 9785, 2022, 1, 553, 6244, 799, 64, 13, 1084, 5707, 264, 15817, 1191, 448, 5257, 7375, 323, 374, 8789, 8661, 369, 46850, 311, 33377, 7707, 311, 27076, 13980, 429, 1373, 803, 304, 30310, 6540, 315, 3151, 5671, 1075, 5538, 6832, 476, 5662, 6832, 382, 2461, 52143, 10887, 19117, 93421, 1119, 821, 8038, 7361, 11, 12831, 279, 330, 37155, 311, 2885, 9965, 9785, 2022, 1, 389, 6244, 799, 64, 1035, 387, 23699, 11, 5310, 421, 807, 525, 8014, 304, 14976, 8357, 13]\n",
      "Final Reasoning Result from Qwen:\n",
      "\n",
      "==================================================\n",
      "To answer the question based on the course details provided:\n",
      "\n",
      "1. **Course 2** - \"Introduction to Data Science Specialization\" by Coursera offers foundational data science skills, which is suitable for beginners as it provides a comprehensive start with various tools.\n",
      "   - This course appears more suitable for beginners compared to other specialized courses that require more advanced knowledge.\n",
      "\n",
      "2. **Course 1** - \"Getting Started with Teaching Data Science in Schools\" on FutureLearn introduces the basics of teaching data science but lacks specific skills and tools like Python, SQL, R programming which are essential.\n",
      "   - This course is better suited for educators or those looking to teach rather than learners who need practical data science knowledge.\n",
      "\n",
      "3. **Course 4** - \"Introduction to Data Science Specialization\" by Coursera offers a more in-depth look into various aspects of data science.\n",
      "   - While it has a higher rating and good positive percentage, it is recommended as a better choice for advanced learners since the specialized courses like this one provide deeper dives into specific skills.\n",
      "\n",
      "4. **Course 3** - \"Introduction to Data Science Specialization\" by Coursera offers foundational skills but doesn't cover the detailed knowledge needed in data science.\n",
      "   - This course ranks lower due to its lack of depth and practical application, which are important for advanced learners.\n",
      "\n",
      "5. **Other Courses**  \n",
      "- Other courses offer a mix of theoretical and practical aspects but may not fully address all specific requirements or use cases for beginners and advanced learners respectively.\n",
      "\n",
      "Final suggestion:\n",
      "For those looking to gain foundational data science skills suitable for beginners, I would recommend \"Introduction to Data Science Specialization\" by Coursera. It provides a comprehensive start with various tools and is generally easier for beginners to grasp compared to specialized courses that require more in-depth knowledge of specific areas like deep learning or machine learning.\n",
      "\n",
      "For learners seeking deeper dives into data science skills, considering the \"Introduction to Data Science Specialization\" on Coursera would be beneficial, especially if they are interested in practical applications.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import ollama\n",
    "\n",
    "# ======== Step 1: Load SBERT Model ========\n",
    "sbert_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# ======== Step 2: Load Courses from JSON File ========\n",
    "with open('D:\\\\Thesis\\\\Courses-Searching\\\\src\\\\db\\\\processed_courses_detail.json', 'r', encoding='utf-8') as file:\n",
    "    courses = json.load(file)\n",
    "\n",
    "# ======== Step 3: Create FAISS Index (Embedding + Search) ========\n",
    "def create_faiss_index(courses):\n",
    "    course_texts = [course[\"title\"] + \" \" + course[\"description\"] for course in courses]\n",
    "    embeddings = sbert_model.encode(course_texts)\n",
    "    \n",
    "    # Create FAISS index\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(np.array(embeddings))\n",
    "    return index, embeddings\n",
    "\n",
    "faiss_index, embeddings = create_faiss_index(courses)\n",
    "\n",
    "# ======== Step 4: Define Retrieval Function ========\n",
    "def retrieve_top_k(query, k=10):\n",
    "    query_embedding = sbert_model.encode([query])\n",
    "    distances, indices = faiss_index.search(np.array(query_embedding), k)\n",
    "    retrieved_courses = [courses[idx] for idx in indices[0]]\n",
    "    return retrieved_courses\n",
    "\n",
    "# ======== Step 5: Define Qwen Reasoning Function ========\n",
    "def contextual_reasoning_qwen(query, retrieved_courses):\n",
    "    # Define the prompt structure with data format explanation\n",
    "    prompt = f\"\"\"\n",
    "You are an AI assistant helping to answer course-related questions.\n",
    "\n",
    "**Task:**  \n",
    "- Analyze the retrieved courses to answer the query.\n",
    "- Use context, reasoning, and comparison if needed.\n",
    "\n",
    "**Data Format:**  \n",
    "Each course has the following attributes:\n",
    "- \"course_id\": Unique ID for the course.\n",
    "- \"title\": Name of the course.\n",
    "- \"url\": Link to the course.\n",
    "- \"description\": Brief overview of the course.\n",
    "- \"category\": Main category of the course.\n",
    "- \"sub_category\": Subcategory if available.\n",
    "- \"course_info\": Language and subtitle information.\n",
    "- \"rating\": Overall user rating (out of 5).\n",
    "- \"reviews\": Total number of reviews and positive percentage.\n",
    "- \"knowledge_requirements\": What the course teaches and prerequisites.\n",
    "- \"learning_path\": Suitable learner level and career paths.\n",
    "- \"instructors\": List of instructor names.\n",
    "\n",
    "**User Query:**  \n",
    "{query}\n",
    "\n",
    "**Retrieved Courses:**  \n",
    "{json.dumps(retrieved_courses, indent=2)}\n",
    "\n",
    "**Instructions:**  \n",
    "- Analyze the courses to determine if they fully or partially answer the query.\n",
    "- For comparative questions (e.g., \"Which is better for beginners?\"), rank or explain.\n",
    "- For unavailable information, reply with the most appropriate courses to the query.\n",
    "\n",
    "**Output:**  \n",
    "Provide a brief reasoning and final suggestion or answer.\"\"\"\n",
    "\n",
    "    # ======== Step 6: Call the Qwen Model via Ollama ========\n",
    "    client = ollama.Client()\n",
    "    print(\"Query:\", query)\n",
    "    print(\"Number of Retrieved Courses:\", len(retrieved_courses))\n",
    "    print(\"Prompt:\", prompt)\n",
    "\n",
    "    response = client.generate(model=\"qwen2.5:1.5b\", prompt=prompt)\n",
    "    print(\"Raw Response:\", response)  # Check if response is None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return {\"response\": response}\n",
    "\n",
    "# ======== Step 7: Execute the Full Pipeline ========\n",
    "query = \"Which course is suitable for beginners in Data Science?\"\n",
    "retrieved = retrieve_top_k(query, k=10)\n",
    "result = contextual_reasoning_qwen(query, retrieved)\n",
    "\n",
    "# ======== Final Output (Cleaned) ========\n",
    "final_text = result[\"response\"].response  # Extract the response text\n",
    "\n",
    "print(\"Final Reasoning Result from Qwen:\\n\")\n",
    "print(\"=\" * 50)\n",
    "print(final_text.strip())  # Now it's safe to use .strip()\n",
    "print(\"=\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Final Reasoning Result from Qwen:\n",
      "\n",
      "The course taught by Andrew Ng is \"Advanced Learning Algorithms.\" This specialization from Coursera covers advanced learning algorithms in depth. The courses are part of a Machine Learning Specialization, focusing on Artificial Neural Networks, Xgboost, Tensorflow, Tree Ensembles, and Advice for Model Development.\n",
      "\n",
      "Andrew Ng was known for creating the original version of Coursera and has extensive experience in machine learning education. He is often associated with teaching advanced algorithms due to his background in artificial intelligence and natural language processing.\n",
      "\n",
      "Given that multiple courses match \"Advanced Learning Algorithms,\" it's likely that Andrew Ng teaches these as part of a larger specialization or course series on machine learning. The suggested courses align well with the title provided by the user, focusing on advanced learning algorithms with strong prerequisites and career paths for professionals in data science fields like AI engineers and data scientists.\n",
      "\n",
      "Final suggestion: Courses taught by Andrew Ng include \"Advanced Learning Algorithms,\" which covers advanced learning algorithms as part of a larger specialization on machine learning. This matches the user's request very closely.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import ollama\n",
    "\n",
    "# ======== Step 1: Load SBERT Model ========\n",
    "sbert_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# ======== Step 2: Load Courses from JSON File ========\n",
    "with open('D:\\\\Thesis\\\\Courses-Searching\\\\src\\\\db\\\\processed_courses_detail.json', 'r', encoding='utf-8') as file:\n",
    "    courses = json.load(file)\n",
    "\n",
    "# ======== Step 3: Create FAISS Index (Embedding + Search) ========\n",
    "def create_faiss_index(courses):\n",
    "    course_texts = []\n",
    "    \n",
    "    for course in courses:\n",
    "        # Extract key attributes with safe defaults\n",
    "        title = course.get(\"title\", \"\")\n",
    "        description = course.get(\"description\", \"\")\n",
    "        category = course.get(\"category\", \"\")\n",
    "        sub_category = course.get(\"sub_category\", \"\")\n",
    "        rating = str(course.get(\"rating\", \"\"))\n",
    "        career_paths = \", \".join(course.get(\"learning_path\", {}).get(\"career_paths\", []))\n",
    "\n",
    "        # Ensure instructors is always a list\n",
    "        instructors = course.get(\"instructors\", [])\n",
    "        if not isinstance(instructors, list):\n",
    "            instructors = [str(instructors)]\n",
    "        instructors = \", \".join(instructors)\n",
    "\n",
    "        # Mark instructors as highly relevant for better retrieval\n",
    "        instructors_text = f\"Instructors: {instructors} (Highly Relevant)\" if instructors else \"\"\n",
    "\n",
    "        # Combine all relevant fields for embeddings\n",
    "        text = f\"{title} {description} {category} {sub_category} {rating} {career_paths} {instructors_text}\"\n",
    "        course_texts.append(text)\n",
    "    \n",
    "    # Generate embeddings\n",
    "    embeddings = sbert_model.encode(course_texts, convert_to_numpy=True)\n",
    "    \n",
    "    # Create FAISS index\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings)\n",
    "    \n",
    "    return index, embeddings\n",
    "\n",
    "# Initialize FAISS index\n",
    "faiss_index, embeddings = create_faiss_index(courses)\n",
    "\n",
    "def retrieve_top_k(query, k=10):\n",
    "    query_embedding = sbert_model.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = faiss_index.search(query_embedding, k)\n",
    "\n",
    "    retrieved_courses = [courses[idx] for idx in indices[0]]\n",
    "\n",
    "    # Additional filtering for direct matches (e.g., instructor search)\n",
    "    for course in courses:\n",
    "        instructors = course.get(\"instructors\", [])\n",
    "        if not isinstance(instructors, list):\n",
    "            instructors = [str(instructors)]  # Convert to list of strings\n",
    "\n",
    "        instructor_text = \", \".join(instructors).lower()\n",
    "        \n",
    "        if query.lower() in instructor_text:\n",
    "            retrieved_courses.insert(0, course)  # Prioritize direct matches\n",
    "\n",
    "    return retrieved_courses[:k]  # Return only the top-k results\n",
    "\n",
    "\n",
    "# ======== Step 5: Define Qwen Reasoning Function ========\n",
    "def contextual_reasoning_qwen(query, retrieved_courses):\n",
    "    # Define the prompt structure with data format explanation\n",
    "    prompt = f\"\"\"\n",
    "You are an AI assistant helping users find the best courses.\n",
    "\n",
    "**Task:**  \n",
    "- Analyze the retrieved courses to answer the query.\n",
    "- Use reasoning and comparison where needed.\n",
    "\n",
    "**Data Format:**  \n",
    "Each course has the following attributes:\n",
    "- \"title\": Course name\n",
    "- \"url\": Course link\n",
    "- \"description\": Course overview\n",
    "- \"category\": Course category\n",
    "- \"rating\": User rating\n",
    "- \"instructors\": List of instructors\n",
    "- \"learning_path\": Suggested learner level and career paths\n",
    "\n",
    "**User Query:**  \n",
    "{query}\n",
    "\n",
    "**Retrieved Courses:**  \n",
    "{json.dumps(retrieved_courses[:5], indent=2)}  # Show only top 5 for clarity\n",
    "\n",
    "**Instructions:**  \n",
    "- Summarize relevant courses for the user.\n",
    "- If the query is about instructors, highlight their courses first.\n",
    "- If multiple courses fit, compare them briefly.\n",
    "- If no exact match, suggest the closest options.\n",
    "\n",
    "**Output Format:**  \n",
    "Provide a **concise answer** with reasoning and a final suggestion.\"\"\"\n",
    "\n",
    "    # ======== Step 6: Call Qwen Model via Ollama ========\n",
    "    client = ollama.Client()\n",
    "\n",
    "    response = client.generate(model=\"qwen2.5:1.5b\", prompt=prompt)\n",
    "\n",
    "    # Extract response safely\n",
    "    final_response = response.response if response and hasattr(response, \"response\") else \"No response generated.\"\n",
    "\n",
    "    return {\"response\": final_response}\n",
    "\n",
    "# ======== Step 7: Execute the Full Pipeline ========\n",
    "query = \"Courses taught by Andrew Ng\"\n",
    "retrieved = retrieve_top_k(query, k=10)\n",
    "result = contextual_reasoning_qwen(query, retrieved)\n",
    "\n",
    "# ======== Final Output ========\n",
    "print(\"=\" * 50)\n",
    "print(\"Final Reasoning Result from Qwen:\\n\")\n",
    "print(result[\"response\"].strip())  # Ensure clean output\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Final Reasoning Result from Qwen:\n",
      "\n",
      "Based on the provided information, there are several courses that meet the criteria of being top-rated with over 90% positive reviews:\n",
      "\n",
      "1. \"Reviews & Metrics for Software Improvements\" by Coursera.org is highly recommended due to its comprehensive focus on software quality monitoring and review techniques.\n",
      "2. \"Information Systems Auditing, Controls and Assurance\" also scores well with a high percentage (94%) of positive feedback.\n",
      "\n",
      "While there are multiple courses that could be considered for the top 5 based on their positive reviews alone, both \"Reviews & Metrics for Software Improvements\" and \"Information Systems Auditing, Controls and Assurance\" align closely with the user's request. Therefore, I suggest focusing on either one if you're looking to explore quality management or auditing in technology-related fields.\n",
      "\n",
      "Final suggestion: Explore either \"Reviews & Metrics for Software Improvements\" or \"Information Systems Auditing, Controls and Assurance.\" Both courses are highly rated and provide valuable insights into software and information systems operations.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======== Step 7: Execute the Full Pipeline ========\n",
    "query = \"Top-rated courses with more than 90% positive reviews\"\n",
    "retrieved = retrieve_top_k(query, k=10)\n",
    "result = contextual_reasoning_qwen(query, retrieved)\n",
    "\n",
    "# ======== Final Output ========\n",
    "print(\"=\" * 50)\n",
    "print(\"Final Reasoning Result from Qwen:\\n\")\n",
    "print(result[\"response\"].strip())  # Ensure clean output\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'course_id': 'Ce744efaf',\n",
       "  'title': 'Reviews & Metrics for Software Improvements',\n",
       "  'url': 'https://www.coursera.org/learn/reviews-and-metrics-for-software-improvements?specialization=product-management',\n",
       "  'description': 'This course covers techniques for monitoring your projects in order to align client needs, project plans, and software production. It focuses on metrics and reviews to track and improve project progress and software quality.',\n",
       "  'category': 'Computer Science',\n",
       "  'sub_category': 'Unknown',\n",
       "  'course_info': {'provider': None,\n",
       "   'type': None,\n",
       "   'language': 'English',\n",
       "   'subtitle_languages': ['Arabic',\n",
       "    'French',\n",
       "    'Portuguese (European)',\n",
       "    'Italian',\n",
       "    'Vietnamese',\n",
       "    'German',\n",
       "    'Russian',\n",
       "    'English',\n",
       "    'Spanish']},\n",
       "  'rating': 4.7,\n",
       "  'positive_percentage': 94.0,\n",
       "  'duration_months': 8.0,\n",
       "  'reviews': {'total_reviews': 1590, 'positive_percentage': 94.0},\n",
       "  'knowledge_requirements': {'teaches': ['Software Metric,Agile Software Development,Software Project Management,Software Metrics'],\n",
       "   'prerequisites': ['Software Metric,Agile Software Development,Software Project Management,Software Metrics']},\n",
       "  'learning_path': {'suitable_for': ['Advanced Learners'],\n",
       "   'career_paths': ['AI Engineer']},\n",
       "  'instructors': ['Kenny Wong']},\n",
       " {'course_id': 'C527e55c7',\n",
       "  'title': 'Information Systems Auditing, Controls and Assurance',\n",
       "  'url': 'https://www.coursera.org/learn/information-systems-audit',\n",
       "  'description': 'The course is awarded The Best Free Online Courses of All Time, and Best Online Courses of the Year (2021 Edition) by Class Central (http://www.classcentral.com).',\n",
       "  'category': 'Information Technology',\n",
       "  'sub_category': 'Unknown',\n",
       "  'course_info': {'provider': None,\n",
       "   'type': None,\n",
       "   'language': 'English',\n",
       "   'subtitle_languages': ['Arabic',\n",
       "    'French',\n",
       "    'Portuguese (European)',\n",
       "    'Italian',\n",
       "    'Vietnamese',\n",
       "    'German',\n",
       "    'Russian',\n",
       "    'English',\n",
       "    'Spanish']},\n",
       "  'rating': 4.7,\n",
       "  'positive_percentage': 94.0,\n",
       "  'duration_months': 8.0,\n",
       "  'reviews': {'total_reviews': 2801, 'positive_percentage': 94.0},\n",
       "  'knowledge_requirements': {'teaches': ['Information Security (INFOSEC),Information Technology (IT) Management,Audit,Risk Management,Change Management'],\n",
       "   'prerequisites': ['Information Security (INFOSEC),Information Technology (IT) Management,Audit,Risk Management,Change Management']},\n",
       "  'learning_path': {'suitable_for': ['Advanced Learners'],\n",
       "   'career_paths': ['AI Engineer']},\n",
       "  'instructors': ['Garvin Percy DIAS']},\n",
       " {'course_id': 'C3f147051',\n",
       "  'title': 'Quality Improvement in Healthcare Organizations',\n",
       "  'url': 'https://www.coursera.org/learn/quality-improvement-in-healthcare-organizations?specialization=healthcare-organization-operations',\n",
       "  'description': 'Have you ever though that healthcare quality could be improved - either where you get health care treatment or where you delivery health care?  Have you ever thought that there should be a way for you to determine the relative quality of your choices? Have you found yourself thinking that there should be a way for you to provide your view and input on the quality of healthcare organization? Or do you work in a healthcare organization and find yourself thinking that there must be better ways to continuously and systematically improve the quality of your healthcare organization? If you have, this course is for you.',\n",
       "  'category': 'Health',\n",
       "  'sub_category': 'Unknown',\n",
       "  'course_info': {'provider': None,\n",
       "   'type': None,\n",
       "   'language': 'English',\n",
       "   'subtitle_languages': ['English']},\n",
       "  'rating': 4.7,\n",
       "  'positive_percentage': 94.0,\n",
       "  'duration_months': 13.0,\n",
       "  'reviews': {'total_reviews': 161, 'positive_percentage': 94.0},\n",
       "  'knowledge_requirements': {'teaches': ['Pharmacy Healthcare Organization Operations,Public Health and Wellness Healthcare Organization Operations,Medical Healthcare Organization Operations,Healthcare Administration,Dental Healthcare Organization Operations'],\n",
       "   'prerequisites': ['Pharmacy Healthcare Organization Operations,Public Health and Wellness Healthcare Organization Operations,Medical Healthcare Organization Operations,Healthcare Administration,Dental Healthcare Organization Operations']},\n",
       "  'learning_path': {'suitable_for': ['Advanced Learners'],\n",
       "   'career_paths': ['AI Engineer']},\n",
       "  'instructors': ['Margaret Kilduff', 'Ph.D.']},\n",
       " {'course_id': 'Ca7f6b072',\n",
       "  'title': 'Fashion Management: Products and Collections',\n",
       "  'url': 'https://www.futurelearn.com/courses/products-collections',\n",
       "  'description': '392\\xa0enrolled on this course',\n",
       "  'category': 'nan',\n",
       "  'sub_category': 'Unknown',\n",
       "  'course_info': {'provider': None,\n",
       "   'type': None,\n",
       "   'language': 'nan',\n",
       "   'subtitle_languages': None},\n",
       "  'rating': None,\n",
       "  'positive_percentage': None,\n",
       "  'duration_months': 3.0,\n",
       "  'reviews': {'total_reviews': 0, 'positive_percentage': None},\n",
       "  'knowledge_requirements': {'teaches': None, 'prerequisites': None},\n",
       "  'learning_path': {'suitable_for': ['Advanced Learners'],\n",
       "   'career_paths': ['AI Engineer']},\n",
       "  'instructors': None},\n",
       " {'course_id': 'Ca7f6b072',\n",
       "  'title': 'Fashion Management: Products and Collections',\n",
       "  'url': 'https://www.futurelearn.com/courses/products-collections',\n",
       "  'description': '392\\xa0enrolled on this course',\n",
       "  'category': 'nan',\n",
       "  'sub_category': 'Unknown',\n",
       "  'course_info': {'provider': None,\n",
       "   'type': None,\n",
       "   'language': 'nan',\n",
       "   'subtitle_languages': None},\n",
       "  'rating': None,\n",
       "  'positive_percentage': None,\n",
       "  'duration_months': 3.0,\n",
       "  'reviews': {'total_reviews': 0, 'positive_percentage': None},\n",
       "  'knowledge_requirements': {'teaches': None, 'prerequisites': None},\n",
       "  'learning_path': {'suitable_for': ['Advanced Learners'],\n",
       "   'career_paths': ['AI Engineer']},\n",
       "  'instructors': None},\n",
       " {'course_id': 'Ca7f6b072',\n",
       "  'title': 'Fashion Management: Products and Collections',\n",
       "  'url': 'https://www.futurelearn.com/courses/products-collections',\n",
       "  'description': '392\\xa0enrolled on this course',\n",
       "  'category': 'nan',\n",
       "  'sub_category': 'Unknown',\n",
       "  'course_info': {'provider': None,\n",
       "   'type': None,\n",
       "   'language': 'nan',\n",
       "   'subtitle_languages': None},\n",
       "  'rating': None,\n",
       "  'positive_percentage': None,\n",
       "  'duration_months': 3.0,\n",
       "  'reviews': {'total_reviews': 0, 'positive_percentage': None},\n",
       "  'knowledge_requirements': {'teaches': None, 'prerequisites': None},\n",
       "  'learning_path': {'suitable_for': ['Advanced Learners'],\n",
       "   'career_paths': ['AI Engineer']},\n",
       "  'instructors': None},\n",
       " {'course_id': 'C4b1992b9',\n",
       "  'title': 'Quality in Construction',\n",
       "  'url': 'https://www.futurelearn.com/courses/construction-quality',\n",
       "  'description': 'Understand the impact of poor quality and how to manage construction quality with this course for construction professionals.',\n",
       "  'category': 'nan',\n",
       "  'sub_category': 'Unknown',\n",
       "  'course_info': {'provider': None,\n",
       "   'type': None,\n",
       "   'language': 'nan',\n",
       "   'subtitle_languages': None},\n",
       "  'rating': None,\n",
       "  'positive_percentage': None,\n",
       "  'duration_months': 3.0,\n",
       "  'reviews': {'total_reviews': 0, 'positive_percentage': None},\n",
       "  'knowledge_requirements': {'teaches': None, 'prerequisites': None},\n",
       "  'learning_path': {'suitable_for': ['Advanced Learners'],\n",
       "   'career_paths': ['AI Engineer']},\n",
       "  'instructors': None},\n",
       " {'course_id': 'C4b1992b9',\n",
       "  'title': 'Quality in Construction',\n",
       "  'url': 'https://www.futurelearn.com/courses/construction-quality',\n",
       "  'description': 'Understand the impact of poor quality and how to manage construction quality with this course for construction professionals.',\n",
       "  'category': 'nan',\n",
       "  'sub_category': 'Unknown',\n",
       "  'course_info': {'provider': None,\n",
       "   'type': None,\n",
       "   'language': 'nan',\n",
       "   'subtitle_languages': None},\n",
       "  'rating': None,\n",
       "  'positive_percentage': None,\n",
       "  'duration_months': 3.0,\n",
       "  'reviews': {'total_reviews': 0, 'positive_percentage': None},\n",
       "  'knowledge_requirements': {'teaches': None, 'prerequisites': None},\n",
       "  'learning_path': {'suitable_for': ['Advanced Learners'],\n",
       "   'career_paths': ['AI Engineer']},\n",
       "  'instructors': None},\n",
       " {'course_id': 'C4b1992b9',\n",
       "  'title': 'Quality in Construction',\n",
       "  'url': 'https://www.futurelearn.com/courses/construction-quality',\n",
       "  'description': 'Understand the impact of poor quality and how to manage construction quality with this course for construction professionals.',\n",
       "  'category': 'nan',\n",
       "  'sub_category': 'Unknown',\n",
       "  'course_info': {'provider': None,\n",
       "   'type': None,\n",
       "   'language': 'nan',\n",
       "   'subtitle_languages': None},\n",
       "  'rating': None,\n",
       "  'positive_percentage': None,\n",
       "  'duration_months': 3.0,\n",
       "  'reviews': {'total_reviews': 0, 'positive_percentage': None},\n",
       "  'knowledge_requirements': {'teaches': None, 'prerequisites': None},\n",
       "  'learning_path': {'suitable_for': ['Advanced Learners'],\n",
       "   'career_paths': ['AI Engineer']},\n",
       "  'instructors': None},\n",
       " {'course_id': 'C4b1992b9',\n",
       "  'title': 'Quality in Construction',\n",
       "  'url': 'https://www.futurelearn.com/courses/construction-quality',\n",
       "  'description': 'Understand the impact of poor quality and how to manage construction quality with this course for construction professionals.',\n",
       "  'category': 'nan',\n",
       "  'sub_category': 'Unknown',\n",
       "  'course_info': {'provider': None,\n",
       "   'type': None,\n",
       "   'language': 'nan',\n",
       "   'subtitle_languages': None},\n",
       "  'rating': None,\n",
       "  'positive_percentage': None,\n",
       "  'duration_months': 3.0,\n",
       "  'reviews': {'total_reviews': 0, 'positive_percentage': None},\n",
       "  'knowledge_requirements': {'teaches': None, 'prerequisites': None},\n",
       "  'learning_path': {'suitable_for': ['Advanced Learners'],\n",
       "   'career_paths': ['AI Engineer']},\n",
       "  'instructors': None}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Python\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Final Reasoning Result from Qwen:\n",
      "\n",
      "==================================================\n",
      "Reasoning: The provided data contains multiple courses titled \"Introduction to Artificial Intelligence (AI)\" but with different specializations. These courses cover various aspects of AI, including use cases, applications, concepts like machine learning and deep learning, ethical considerations, and job-related issues.\n",
      "\n",
      "Final suggestion:\n",
      "All these courses provide valuable information on artificial intelligence across different domains such as technology, business, key technologies for innovation, and data science. However, based on the provided details, selecting a course with a specialization in \"AI-foundations-for-everyone\" or \"key-technologies-for-business\" might offer deeper insights tailored to your specific interests within AI's applications or broader impact on various industries.\n",
      "\n",
      "Choosing one of these specialized courses would likely provide more relevant and applicable knowledge for your professional goals.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import ollama\n",
    "\n",
    "# ======== Step 1: Load SBERT Model ========\n",
    "sbert_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# ======== Step 2: Load Courses from JSON File ========\n",
    "with open('D:\\\\Thesis\\\\Courses-Searching\\\\src\\\\db\\\\processed_courses_detail.json', 'r', encoding='utf-8') as file:\n",
    "    courses = json.load(file)\n",
    "\n",
    "# ======== Step 3: Create FAISS Index (Embedding + Search) ========\n",
    "def create_faiss_index(courses):\n",
    "    course_texts = []\n",
    "    for course in courses:\n",
    "        title = course.get(\"title\", \"\")\n",
    "        description = course.get(\"description\", \"\")\n",
    "        instructors = course.get(\"instructors\", [])\n",
    "        if not isinstance(instructors, list):\n",
    "            instructors = [str(instructors)]\n",
    "        instructors = \", \".join(instructors)\n",
    "        knowledge_reqs = course.get(\"knowledge_requirements\", \"\")\n",
    "        course_info = course.get(\"course_info\", \"\")\n",
    "        text = f\"{title} {description} {instructors} {knowledge_reqs} {course_info}\"\n",
    "        course_texts.append(text)\n",
    "\n",
    "    embeddings = sbert_model.encode(course_texts, convert_to_numpy=True)\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings)\n",
    "    return index, embeddings\n",
    "\n",
    "faiss_index, embeddings = create_faiss_index(courses)\n",
    "\n",
    "# ======== Step 4: Extract Query Intent Using Qwen ========\n",
    "def get_query_intent(query):\n",
    "    prompt = f\"\"\"\n",
    "You are an AI assistant that extracts structured search filters from user queries.\n",
    "\n",
    "**Task:**\n",
    "Analyze the user query and identify relevant attributes for filtering.\n",
    "\n",
    "**Dataset Attributes:**\n",
    "- \"title\": Course name.\n",
    "- \"instructors\": List of instructor names.\n",
    "- \"category\": Main category (e.g., Data Science, AI, Business).\n",
    "- \"sub_category\": Subcategory if available.\n",
    "- \"knowledge_requirements.teaches\": Topics taught in the course.\n",
    "- \"knowledge_requirements.prerequisites\": Prerequisites for the course.\n",
    "- \"learning_path.suitable_for\": Suitable learner level (Beginner, Advanced).\n",
    "- \"learning_path.career_paths\": Relevant career paths (e.g., Data Scientist, Engineer).\n",
    "- \"language\": Language of instruction.\n",
    "- \"rating\": Course rating.\n",
    "- \"reviews.total_reviews\": Number of reviews.\n",
    "\n",
    "**User Query:**\n",
    "\"{query}\"\n",
    "\n",
    "**Instructions:**\n",
    "- Identify relevant attributes based on the user query.\n",
    "- Provide the search filters in valid JSON format.\n",
    "\n",
    "**Output Example:**\n",
    "{{\n",
    "    \"filters\": {{\n",
    "        \"category\": \"Data Science\",\n",
    "        \"learning_path.suitable_for\": \"Beginner\"\n",
    "    }}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    response = ollama.Client().generate(model=\"qwen2.5:1.5b\", prompt=prompt)\n",
    "\n",
    "    # Ensure response is structured JSON\n",
    "    try:\n",
    "        intent = json.loads(response.response)\n",
    "        return intent\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"filters\": {}}  # Fallback if Qwen fails\n",
    "\n",
    "\n",
    "# ======== Step 5: Retrieve Courses Using FAISS ========\n",
    "def retrieve_top_k(query, filters, k=10):\n",
    "    query_embedding = sbert_model.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = faiss_index.search(query_embedding, k)\n",
    "    retrieved_courses = [courses[idx] for idx in indices[0]]\n",
    "\n",
    "    filtered_courses = []\n",
    "    for course in retrieved_courses:\n",
    "        match = True\n",
    "        for key, value in filters.items():\n",
    "            if key in course and value.lower() not in str(course[key]).lower():\n",
    "                match = False\n",
    "        if match:\n",
    "            filtered_courses.append(course)\n",
    "\n",
    "    return filtered_courses[:k]\n",
    "\n",
    "# ======== Step 6: Generate Final Response Using Qwen ========\n",
    "def contextual_reasoning_qwen(query, retrieved_courses):\n",
    "    prompt = f\"\"\"\n",
    "You are an AI assistant helping to answer course-related questions.\n",
    "\n",
    "**User Query:**\n",
    "{query}\n",
    "\n",
    "**Retrieved Courses:**\n",
    "{json.dumps(retrieved_courses, indent=2)}\n",
    "\n",
    "Provide a brief reasoning and final suggestion.\n",
    "\"\"\"\n",
    "    \n",
    "    client = ollama.Client()\n",
    "    response = client.generate(model=\"qwen2.5:1.5b\", prompt=prompt)\n",
    "    \n",
    "    return {\"response\": response.response}\n",
    "\n",
    "# ======== Step 7: Execute the Full Pipeline ========\n",
    "query = \"Which courses are best for beginners in AI?\"\n",
    "query_intent = get_query_intent(query)\n",
    "filters = query_intent.get(\"filters\", {})\n",
    "\n",
    "retrieved = retrieve_top_k(query, filters, k=10)\n",
    "result = contextual_reasoning_qwen(query, retrieved)\n",
    "\n",
    "print(\"Final Reasoning Result from Qwen:\\n\")\n",
    "print(\"=\" * 50)\n",
    "print(result[\"response\"].strip())  \n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filters': {}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filters': {'instructors': '', 'title': '', 'category': 'AI', 'sub_category': 'Beginner'}}\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import json\n",
    "\n",
    "def get_query_intent(query):\n",
    "    client = ollama.Client()\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "You are an AI assistant that extracts structured filters from course search queries.\n",
    "\n",
    "**Task:**\n",
    "- From the user's query, infer the best matching filters.\n",
    "- Match query terms like \"AI\" to \"Data Science\" if reasonable.\n",
    "- Only use the following attributes:\n",
    "  - \"title\"\n",
    "  - \"instructors\"\n",
    "  - \"category\"\n",
    "  - \"sub_category\"\n",
    "  - \"knowledge_requirements.teaches\"\n",
    "  - \"knowledge_requirements.prerequisites\"\n",
    "  - \"learning_path.suitable_for\"\n",
    "  - \"learning_path.career_paths\"\n",
    "  - \"course_info.language\"\n",
    "  - \"rating\"\n",
    "  - \"reviews.total_reviews\"\n",
    "- Output ONLY valid JSON like:\n",
    "  {\n",
    "    \"filters\": {\n",
    "      \"category\": \"Data Science\",\n",
    "      \"learning_path.suitable_for\": \"Beginner\"\n",
    "    }\n",
    "  }\n",
    "- If nothing matches, output {\"filters\": {}}\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"User Query: {query}\"\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat(model=\"qwen2.5:1.5b\", messages=messages)\n",
    "    \n",
    "    try:\n",
    "        intent = json.loads(response['message']['content'])\n",
    "        return intent\n",
    "    except (json.JSONDecodeError, KeyError):\n",
    "        return {\"filters\": {}}  # Fallback if parsing fails\n",
    "\n",
    "# Example usage\n",
    "query = \"Which courses are best for beginners in AI?\"\n",
    "query_intent = get_query_intent(query)\n",
    "print(query_intent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in processing query intent: Expecting value: line 1 column 1 (char 0)\n",
      "Final Reasoning Result from Qwen:\n",
      "\n",
      "==================================================\n",
      "Based on the available data, we can conclude that several courses related to artificial intelligence are offered by Coursera. The courses cover various aspects of AI, including machine learning, deep learning, neural networks, ethics in AI, and careers in AI.\n",
      "\n",
      "The final suggestion would be to consider enrolling in a course like \"Introduction to Artificial Intelligence\" from the list above, as it seems to offer comprehensive coverage of artificial intelligence concepts and applications. This could provide valuable knowledge for those interested in pursuing a career in data science or related fields.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import ollama\n",
    "\n",
    "# ======== Step 1: Load SBERT Model ========\n",
    "sbert_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# ======== Step 2: Load Courses from JSON File ========\n",
    "with open('D:\\\\Thesis\\\\Courses-Searching\\\\src\\\\db\\\\processed_courses_detail.json', 'r', encoding='utf-8') as file:\n",
    "    courses = json.load(file)\n",
    "\n",
    "# ======== Step 3: Create FAISS Index (Embedding + Search) ========\n",
    "def create_faiss_index(courses, nlist=100):\n",
    "    course_texts = []\n",
    "    for course in courses:\n",
    "        title = course.get(\"title\", \"\")\n",
    "        description = course.get(\"description\", \"\")\n",
    "        instructors = course.get(\"instructors\", [])\n",
    "        if not isinstance(instructors, list):\n",
    "            instructors = [str(instructors)]\n",
    "        instructors = \", \".join(instructors)\n",
    "        knowledge_reqs = course.get(\"knowledge_requirements\", \"\")\n",
    "        course_info = course.get(\"course_info\", \"\")\n",
    "        text = f\"{title} {description} {instructors} {knowledge_reqs} {course_info}\"\n",
    "        course_texts.append(text)\n",
    "\n",
    "    embeddings = sbert_model.encode(course_texts, convert_to_numpy=True)\n",
    "    dimension = embeddings.shape[1]\n",
    "    \n",
    "    # Create FAISS index with IVF (Inverted File) index for faster retrieval\n",
    "    quantizer = faiss.IndexFlatL2(dimension)  # Flat index for quantization\n",
    "    index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_L2)\n",
    "    \n",
    "    # Train the index (required before adding data)\n",
    "    index.train(embeddings)\n",
    "    \n",
    "    # Add embeddings to the index\n",
    "    index.add(embeddings)\n",
    "    return index, embeddings\n",
    "\n",
    "\n",
    "faiss_index, embeddings = create_faiss_index(courses)\n",
    "\n",
    "# ======== Step 4: Extract Query Intent Using Qwen ========\n",
    "def get_query_intent(query):\n",
    "    client = ollama.Client()\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "You are an AI assistant that extracts structured filters from course search queries.\n",
    "\n",
    "**Task:**\n",
    "- From the user's query, infer the best matching filters.\n",
    "- Match query terms like \"AI\" to \"Data Science\" if reasonable.\n",
    "- Only use the following attributes:\n",
    "  - \"title\"\n",
    "  - \"instructors\"\n",
    "  - \"category\"\n",
    "  - \"sub_category\"\n",
    "  - \"knowledge_requirements.teaches\"\n",
    "  - \"knowledge_requirements.prerequisites\"\n",
    "  - \"learning_path.suitable_for\"\n",
    "  - \"learning_path.career_paths\"\n",
    "  - \"course_info.language\"\n",
    "  - \"rating\"\n",
    "  - \"reviews.total_reviews\"\n",
    "- Output ONLY valid JSON like:\n",
    "  {\n",
    "    \"filters\": {\n",
    "      \"category\": \"Data Science\",\n",
    "      \"learning_path.suitable_for\": \"Beginner\"\n",
    "    }\n",
    "  }\n",
    "- If nothing matches, output {\"filters\": {}}\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"User Query: {query}\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat(model=\"qwen2.5:1.5b\", messages=messages)\n",
    "        intent = json.loads(response['message']['content'])\n",
    "        return intent\n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"Error in processing query intent: {e}\")\n",
    "        return {\"filters\": {}}  # Fallback if parsing fails\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return {\"filters\": {}}\n",
    "\n",
    "# ======== Step 5: Retrieve Courses Using FAISS ========\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def retrieve_top_k(query, filters, k=10):\n",
    "    query_embedding = sbert_model.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = faiss_index.search(query_embedding, k)\n",
    "    retrieved_courses = [courses[idx] for idx in indices[0]]\n",
    "\n",
    "    filtered_courses = []\n",
    "    for course in retrieved_courses:\n",
    "        match = True\n",
    "        for key, value in filters.items():\n",
    "            if key in course:\n",
    "                # Use fuzzy matching to allow partial matches (case-insensitive)\n",
    "                course_value = str(course[key]).lower()\n",
    "                if fuzz.partial_ratio(value.lower(), course_value) < 80:  # Adjust threshold as needed\n",
    "                    match = False\n",
    "                    break\n",
    "        if match:\n",
    "            filtered_courses.append(course)\n",
    "\n",
    "    return filtered_courses[:k]\n",
    "\n",
    "\n",
    "# ======== Step 6: Generate Final Response Using Qwen ========\n",
    "def contextual_reasoning_qwen(query, retrieved_courses):\n",
    "    prompt = f\"\"\"\n",
    "You are an AI assistant helping to answer course-related questions.\n",
    "\n",
    "**User Query:**\n",
    "{query}\n",
    "\n",
    "**Retrieved Courses:**\n",
    "{json.dumps(retrieved_courses, indent=2)}\n",
    "\n",
    "Provide a brief reasoning and final suggestion.\n",
    "\"\"\"\n",
    "    try:\n",
    "        client = ollama.Client()\n",
    "        response = client.generate(model=\"qwen2.5:1.5b\", prompt=prompt)\n",
    "        return {\"response\": response.response}\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return {\"response\": \"An error occurred while processing the response.\"}\n",
    "\n",
    "\n",
    "# ======== Step 7: Execute the Full Pipeline ========\n",
    "query = \"Which courses are best for beginners in AI?\"\n",
    "query_intent = get_query_intent(query)\n",
    "filters = query_intent.get(\"filters\", {})\n",
    "\n",
    "retrieved = retrieve_top_k(query, filters, k=10)\n",
    "result = contextual_reasoning_qwen(query, retrieved)\n",
    "\n",
    "print(\"Final Reasoning Result from Qwen:\\n\")\n",
    "print(\"=\" * 50)\n",
    "print(result[\"response\"].strip())  \n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filters': {'title': 'AI', 'learning_path.suitable_for': 'Beginner'}}\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import json\n",
    "\n",
    "def get_query_intent(query):\n",
    "    client = ollama.Client()\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "You are an AI assistant that extracts structured filters from course search queries.\n",
    "\n",
    "**Task:**\n",
    "- From the user's query, infer the best matching filters.\n",
    "- Match query terms like \"AI\" to \"Data Science\" if reasonable.\n",
    "- Only use the following attributes:\n",
    "  - \"title\"\n",
    "  - \"instructors\"\n",
    "  - \"category\"\n",
    "  - \"sub_category\"\n",
    "  - \"knowledge_requirements.teaches\"\n",
    "  - \"knowledge_requirements.prerequisites\"\n",
    "  - \"learning_path.suitable_for\"\n",
    "  - \"learning_path.career_paths\"\n",
    "  - \"course_info.language\"\n",
    "  - \"rating\"\n",
    "  - \"reviews.total_reviews\"\n",
    "- Output ONLY valid JSON like:\n",
    "  {\n",
    "    \"filters\": {\n",
    "      \"category\": \"Data Science\",\n",
    "      \"learning_path.suitable_for\": \"Beginner\"\n",
    "    }\n",
    "  }\n",
    "- If nothing matches, output {\"filters\": {}}\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"User Query: {query}\"\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat(model=\"qwen2.5:1.5b\", messages=messages)\n",
    "    \n",
    "    try:\n",
    "        intent = json.loads(response['message']['content'])\n",
    "        return intent\n",
    "    except (json.JSONDecodeError, KeyError):\n",
    "        return {\"filters\": {}}  # Fallback if parsing fails\n",
    "\n",
    "# Example usage\n",
    "query = \"Which courses are best for beginners in AI?\"\n",
    "query_intent = get_query_intent(query)\n",
    "print(query_intent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filters': {'title': 'AI', 'learning_path.suitable_for': 'Beginner'}}\n"
     ]
    }
   ],
   "source": [
    "print(query_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Reasoning Result from Qwen:\n",
      "\n",
      "==================================================\n",
      "Based on the information provided, there are multiple courses in the Coursera catalog that cover Artificial Intelligence (AI), including:\n",
      "\n",
      "1. \"Introduction to Artificial Intelligence\" by Google AI - This is an introductory course focused on AI concepts and applications.\n",
      "\n",
      "2. \"Artificial Intelligence with Python\" by Deep Learning Course - This course uses Python programming for AI projects and covers machine learning, neural networks, and deep learning algorithms.\n",
      "\n",
      "3. \"Applied Machine Learning in R: Fundamentals of Data Science\" by Coursera - This course focuses on practical data science using R and applies machine learning techniques to real-world problems.\n",
      "\n",
      "4. \"Introduction to Artificial Intelligence (AI)\" by University of New South Wales (UNSW) - This is a beginner-friendly course that introduces AI concepts through logical reasoning, programming, and problem-solving exercises.\n",
      "\n",
      "5. \"Artificial Intelligence with JavaScript\" by Coursera - This course uses JavaScript for building AI solutions and covers natural language processing, computer vision, and reinforcement learning.\n",
      "\n",
      "6. \"Introduction to Machine Learning in Python: Handling Bias and Fairness\" by Harvard University on Coursera - This course focuses specifically on addressing bias and fairness in machine learning algorithms using Python programming.\n",
      "\n",
      "7. \"Machine Learning A-Z (Complete Course) - Practical AI for Beginners\" by Microsoft, Data Science Central, and Udemy on Coursera - While not exclusively an AI course, this comprehensive guide covers many aspects of AI, including natural language processing, computer vision, and reinforcement learning.\n",
      "\n",
      "8. \"Hands-On Machine Learning with Scikit-Learn and TensorFlow: Skills You Can Use Today\" by Packt Publishing (part of the Coursera catalog) - This book is more practical in nature and focuses on Python-based machine learning tools like scikit-learn and TensorFlow.\n",
      "\n",
      "Final suggestion:\n",
      "Given the variety of AI-related courses available, learners should choose one that best fits their level of experience or specific interests. For beginners, \"Introduction to Artificial Intelligence\" by Google AI might be a good starting point due to its accessibility and intuitive explanations. Those looking for practical applications could benefit from \"Machine Learning A-Z,\" which includes real-world examples in Python. If the goal is to master machine learning with TensorFlow, \"Hands-On Machine Learning with Scikit-Learn and TensorFlow\" is highly recommended.\n",
      "\n",
      "In summary, Coursera offers a wide range of AI courses that cater to different levels and interests, making it an ideal resource for anyone looking to learn about or apply artificial intelligence in various fields.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "filters = query_intent.get(\"filters\", {})\n",
    "\n",
    "retrieved = retrieve_top_k(query, filters, k=10)\n",
    "result = contextual_reasoning_qwen(query, retrieved)\n",
    "\n",
    "print(\"Final Reasoning Result from Qwen:\\n\")\n",
    "print(\"=\" * 50)\n",
    "print(result[\"response\"].strip())  \n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'AI', 'learning_path.suitable_for': 'Beginner'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Intent Result:\n",
      "{\n",
      "  \"filters\": {\n",
      "    \"category\": \"AI\",\n",
      "    \"learning_path.suitable_for\": \"Beginner\"\n",
      "  }\n",
      "}\n",
      "Final Reasoning Result from Qwen:\n",
      "\n",
      "==================================================\n",
      "The user's question is somewhat unclear as the \"courses\" mentioned do not exist. However, I can suggest some popular introductory AI courses that one might find online through websites like Coursera, Udemy, or edX.\n",
      "\n",
      "**Reasoning:**\n",
      "1. **Coursera**: Offers a range of beginner-friendly AI courses from universities and top tech companies.\n",
      "2. **Udemy**: Provides various AI tutorials on practical skills with hands-on projects.\n",
      "3. **edX**: Features courses taught by MIT and other leading institutions in the field.\n",
      "\n",
      "**Final Suggestion:**\n",
      "For beginners in AI, I would recommend starting with introductory courses that focus on machine learning algorithms, natural language processing, computer vision basics, and data analysis techniques. Look for courses that cover Python programming as it is widely used in AI development.\n",
      "\n",
      "Here are some beginner-friendly AI course recommendations:\n",
      "\n",
      "- **Machine Learning Specialization by Andrew Ng**: On Coursera, this specialization covers various aspects of machine learning using Python.\n",
      "- **Introduction to Artificial Intelligence (AI) by Udacity** on Udemy: This is a free online course that introduces you to the concepts and applications of artificial intelligence.\n",
      "- **Computer Vision Basics by MIT OpenCourseWare**: While not directly an AI class, it's foundational for understanding image processing and computer vision which are crucial in modern AI.\n",
      "\n",
      "These courses provide theoretical knowledge as well as practical experience through projects.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ollama\n",
    "\n",
    "# ======== Step 4: Extract Query Intent Using Qwen ========\n",
    "def get_query_intent(query):\n",
    "    client = ollama.Client()\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "You are an AI assistant that extracts structured filters from course search queries.\n",
    "\n",
    "**Task:**\n",
    "- From the user's query, infer the best matching filters.\n",
    "- Match query terms like \"AI\" to \"Data Science\" if reasonable.\n",
    "- Only use the following attributes:\n",
    "  - \"title\"\n",
    "  - \"instructors\"\n",
    "  - \"category\"\n",
    "  - \"sub_category\"\n",
    "  - \"knowledge_requirements.teaches\"\n",
    "  - \"knowledge_requirements.prerequisites\"\n",
    "  - \"learning_path.suitable_for\"\n",
    "  - \"learning_path.career_paths\"\n",
    "  - \"course_info.language\"\n",
    "  - \"rating\"\n",
    "  - \"reviews.total_reviews\"\n",
    "- Output ONLY valid JSON like:\n",
    "  {\n",
    "    \"filters\": {\n",
    "      \"category\": \"Data Science\",\n",
    "      \"learning_path.suitable_for\": \"Beginner\"\n",
    "    }\n",
    "  }\n",
    "- If nothing matches, output {\"filters\": {}}\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"User Query: {query}\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat(model=\"qwen2.5:1.5b\", messages=messages)\n",
    "        intent = json.loads(response['message']['content'])\n",
    "        return intent\n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"Error in processing query intent: {e}\")\n",
    "        return {\"filters\": {}}  # Fallback if parsing fails\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return {\"filters\": {}}\n",
    "\n",
    "# ======== Step 5: Execute the Query Intent Check ========\n",
    "query = \"Which courses are best for beginners in AI?\"\n",
    "query_intent = get_query_intent(query)\n",
    "\n",
    "# In kết quả của query_intent\n",
    "print(\"Query Intent Result:\")\n",
    "print(json.dumps(query_intent, indent=2))  # Chỉ in kết quả intent\n",
    "\n",
    "# ======== Step 6: (Optional) If needed, proceed to FAISS retrieval or other processing ========\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# ======== Step 1: Load SBERT Model ========\n",
    "sbert_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# ======== Step 2: Load Courses from JSON File ========\n",
    "with open('D:\\\\Thesis\\\\Courses-Searching\\\\src\\\\db\\\\processed_courses_detail.json', 'r', encoding='utf-8') as file:\n",
    "    courses = json.load(file)\n",
    "\n",
    "# ======== Step 3: Create FAISS Index (Embedding + Search) ========\n",
    "def create_faiss_index(courses, nlist=100):\n",
    "    course_texts = []\n",
    "    for course in courses:\n",
    "        title = course.get(\"title\", \"\")\n",
    "        description = course.get(\"description\", \"\")\n",
    "        instructors = course.get(\"instructors\", [])\n",
    "        if not isinstance(instructors, list):\n",
    "            instructors = [str(instructors)]\n",
    "        instructors = \", \".join(instructors)\n",
    "        knowledge_reqs = course.get(\"knowledge_requirements\", \"\")\n",
    "        course_info = course.get(\"course_info\", \"\")\n",
    "        text = f\"{title} {description} {instructors} {knowledge_reqs} {course_info}\"\n",
    "        course_texts.append(text)\n",
    "\n",
    "    embeddings = sbert_model.encode(course_texts, convert_to_numpy=True)\n",
    "    dimension = embeddings.shape[1]\n",
    "    \n",
    "    # Create FAISS index with IVF (Inverted File) index for faster retrieval\n",
    "    quantizer = faiss.IndexFlatL2(dimension)  # Flat index for quantization\n",
    "    index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_L2)\n",
    "    \n",
    "    # Train the index (required before adding data)\n",
    "    index.train(embeddings)\n",
    "    \n",
    "    # Add embeddings to the index\n",
    "    index.add(embeddings)\n",
    "    return index, embeddings\n",
    "\n",
    "\n",
    "faiss_index, embeddings = create_faiss_index(courses)\n",
    "\n",
    "# ======== Step 7: Retrieve Courses Using FAISS ========\n",
    "def retrieve_top_k(query, filters, k=10):\n",
    "    query_embedding = sbert_model.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = faiss_index.search(query_embedding, k)\n",
    "    retrieved_courses = [courses[idx] for idx in indices[0]]\n",
    "\n",
    "    filtered_courses = []\n",
    "    for course in retrieved_courses:\n",
    "        match = True\n",
    "        for key, value in filters.items():\n",
    "            if key in course:\n",
    "                # Use fuzzy matching to allow partial matches (case-insensitive)\n",
    "                course_value = str(course[key]).lower()\n",
    "                if fuzz.partial_ratio(value.lower(), course_value) < 80:  # Adjust threshold as needed\n",
    "                    match = False\n",
    "                    break\n",
    "        if match:\n",
    "            filtered_courses.append(course)\n",
    "\n",
    "    return filtered_courses[:k]\n",
    "\n",
    "\n",
    "# ======== Step 8: Generate Final Response Using Qwen ========\n",
    "def contextual_reasoning_qwen(query, retrieved_courses):\n",
    "    prompt = f\"\"\"\n",
    "You are an AI assistant helping to answer course-related questions.\n",
    "\n",
    "**User Query:**\n",
    "{query}\n",
    "\n",
    "**Retrieved Courses:**\n",
    "{json.dumps(retrieved_courses, indent=2)}\n",
    "\n",
    "Provide a brief reasoning and final suggestion.\n",
    "\"\"\"\n",
    "    try:\n",
    "        client = ollama.Client()\n",
    "        response = client.generate(model=\"qwen2.5:1.5b\", prompt=prompt)\n",
    "        return {\"response\": response.response}\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return {\"response\": \"An error occurred while processing the response.\"}\n",
    "\n",
    "\n",
    "# ======== Step 9: Execute the Full Pipeline ========\n",
    "if query_intent.get(\"filters\"):\n",
    "    filters = query_intent.get(\"filters\", {})\n",
    "    retrieved = retrieve_top_k(query, filters, k=10)\n",
    "    result = contextual_reasoning_qwen(query, retrieved)\n",
    "\n",
    "    print(\"Final Reasoning Result from Qwen:\\n\")\n",
    "    print(\"=\" * 50)\n",
    "    print(result[\"response\"].strip())  \n",
    "    print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Intent Result:\n",
      "{\n",
      "  \"filters\": {\n",
      "    \"category\": \"Data Science\",\n",
      "    \"knowledge_requirements.teaches\": \"AI\",\n",
      "    \"course_info.language\": \"English\",\n",
      "    \"learning_path.suitable_for\": \"Beginner\",\n",
      "    \"rating\": \"4.5\"\n",
      "  }\n",
      "}\n",
      "Final Reasoning Result from Qwen:\n",
      "\n",
      "==================================================\n",
      "Since no relevant AI courses were found, I will suggest creating or identifying new courses based on the following criteria:\n",
      "1. The course should be beginner-level.\n",
      "2. It should cover AI topics using English as the primary language.\n",
      "3. It has a rating above 4.5.\n",
      "\n",
      "Based on these conditions, here's an example of what such a course might look like:\n",
      "\n",
      "**Course Title: \"Introduction to Artificial Intelligence for Beginners in English\"**\n",
      "\n",
      "This course would likely start with basic concepts:\n",
      "- Introduction to artificial intelligence\n",
      "- History and importance of AI\n",
      "- Key areas in AI development (e.g., machine learning, natural language processing)\n",
      "\n",
      "It could then progress through more technical topics at a beginner level:\n",
      "- Programming languages commonly used in AI: Python, JavaScript\n",
      "- Basic concepts in programming that are relevant for AI (e.g., loops, variables)\n",
      "- An introduction to basic algorithms and data structures\n",
      "\n",
      "The course would likely include practical exercises and projects where learners can implement what they've learned, using simple tools like Python scripts or HTML/CSS/JavaScript.\n",
      "\n",
      "After the foundational material, it could introduce more advanced topics:\n",
      "- Introduction to neural networks\n",
      "- Overview of machine learning techniques (e.g., supervised vs. unsupervised)\n",
      "- Basic concepts in AI ethics and biases\n",
      "\n",
      "This course would be continuously updated based on feedback from learners, ensuring that both fundamental knowledge and cutting-edge developments in the field are covered.\n",
      "\n",
      "With these detailed suggestions, we should be able to find or create a suitable beginner-level AI course using English that meets your criteria.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ollama\n",
    "\n",
    "# ======== Step 4: Extract Query Intent Using Qwen ========\n",
    "# Assuming the intent includes multiple attributes like 'category', 'rating', etc.\n",
    "\n",
    "def get_query_intent(query):\n",
    "    client = ollama.Client()\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "You are an AI assistant that extracts structured filters from course search queries.\n",
    "\n",
    "**Task:**\n",
    "- From the user's query, infer the best matching filters.\n",
    "- Match query terms like \"AI\" to \"Data Science\" if reasonable.\n",
    "- Only use the following attributes:\n",
    "  - \"title\"\n",
    "  - \"instructors\"\n",
    "  - \"category\"\n",
    "  - \"sub_category\"\n",
    "  - \"knowledge_requirements.teaches\"\n",
    "  - \"knowledge_requirements.prerequisites\"\n",
    "  - \"learning_path.suitable_for\"\n",
    "  - \"learning_path.career_paths\"\n",
    "  - \"course_info.language\"\n",
    "  - \"rating\"\n",
    "  - \"reviews.total_reviews\"\n",
    "- Output ONLY valid JSON like:\n",
    "  {\n",
    "    \"filters\": {\n",
    "      \"category\": \"Data Science\",\n",
    "      \"learning_path.suitable_for\": \"Beginner\",\n",
    "      \"rating\": \"4.5\",\n",
    "      \"course_info.language\": \"English\"\n",
    "    }\n",
    "  }\n",
    "- If nothing matches, output {\"filters\": {}}\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"User Query: {query}\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat(model=\"qwen2.5:1.5b\", messages=messages)\n",
    "        intent = json.loads(response['message']['content'])\n",
    "        return intent\n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"Error in processing query intent: {e}\")\n",
    "        return {\"filters\": {}}  # Fallback if parsing fails\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return {\"filters\": {}}\n",
    "\n",
    "query = \"I am looking for AI courses in English for beginners with a rating above 4.5\"\n",
    "query_intent = get_query_intent(query)\n",
    "\n",
    "# Print the filters returned\n",
    "print(\"Query Intent Result:\")\n",
    "print(json.dumps(query_intent, indent=2))  # Checking the filters returned\n",
    "\n",
    "\n",
    "\n",
    "# ======== Step 6: (Optional) If needed, proceed to FAISS retrieval or other processing ========\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# ======== Step 1: Load SBERT Model ========\n",
    "sbert_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# ======== Step 2: Load Courses from JSON File ========\n",
    "with open('D:\\\\Thesis\\\\Courses-Searching\\\\src\\\\db\\\\processed_courses_detail.json', 'r', encoding='utf-8') as file:\n",
    "    courses = json.load(file)\n",
    "\n",
    "# ======== Step 3: Create FAISS Index (Embedding + Search) ========\n",
    "def create_faiss_index(courses, nlist=100):\n",
    "    course_texts = []\n",
    "    for course in courses:\n",
    "        title = course.get(\"title\", \"\")\n",
    "        description = course.get(\"description\", \"\")\n",
    "        instructors = course.get(\"instructors\", [])\n",
    "        if not isinstance(instructors, list):\n",
    "            instructors = [str(instructors)]\n",
    "        instructors = \", \".join(instructors)\n",
    "        knowledge_reqs = course.get(\"knowledge_requirements\", \"\")\n",
    "        course_info = course.get(\"course_info\", \"\")\n",
    "        text = f\"{title} {description} {instructors} {knowledge_reqs} {course_info}\"\n",
    "        course_texts.append(text)\n",
    "\n",
    "    embeddings = sbert_model.encode(course_texts, convert_to_numpy=True)\n",
    "    dimension = embeddings.shape[1]\n",
    "    \n",
    "    # Create FAISS index with IVF (Inverted File) index for faster retrieval\n",
    "    quantizer = faiss.IndexFlatL2(dimension)  # Flat index for quantization\n",
    "    index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_L2)\n",
    "    \n",
    "    # Train the index (required before adding data)\n",
    "    index.train(embeddings)\n",
    "    \n",
    "    # Add embeddings to the index\n",
    "    index.add(embeddings)\n",
    "    return index, embeddings\n",
    "\n",
    "\n",
    "faiss_index, embeddings = create_faiss_index(courses)\n",
    "\n",
    "# ======== Step 7: Retrieve Courses Using FAISS ========\n",
    "def retrieve_top_k(query, filters, k=10):\n",
    "    query_embedding = sbert_model.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = faiss_index.search(query_embedding, k)\n",
    "    retrieved_courses = [courses[idx] for idx in indices[0]]\n",
    "\n",
    "    filtered_courses = []\n",
    "    for course in retrieved_courses:\n",
    "        match = True\n",
    "        for key, value in filters.items():\n",
    "            if key in course:\n",
    "                # Use fuzzy matching to allow partial matches (case-insensitive)\n",
    "                course_value = str(course[key]).lower()\n",
    "                if fuzz.partial_ratio(value.lower(), course_value) < 80:  # Adjust threshold as needed\n",
    "                    match = False\n",
    "                    break\n",
    "        if match:\n",
    "            filtered_courses.append(course)\n",
    "\n",
    "    return filtered_courses[:k]\n",
    "\n",
    "\n",
    "\n",
    "# ======== Step 8: Generate Final Response Using Qwen ========\n",
    "def contextual_reasoning_qwen(query, retrieved_courses):\n",
    "    prompt = f\"\"\"\n",
    "You are an AI assistant helping to answer course-related questions.\n",
    "\n",
    "**User Query:**\n",
    "{query}\n",
    "\n",
    "**Retrieved Courses:**\n",
    "{json.dumps(retrieved_courses, indent=2)}\n",
    "\n",
    "Provide a brief reasoning and final suggestion.\n",
    "\"\"\"\n",
    "    try:\n",
    "        client = ollama.Client()\n",
    "        response = client.generate(model=\"qwen2.5:1.5b\", prompt=prompt)\n",
    "        return {\"response\": response.response}\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return {\"response\": \"An error occurred while processing the response.\"}\n",
    "\n",
    "\n",
    "# ======== Step 9: Execute the Full Pipeline ========\n",
    "if query_intent.get(\"filters\"):\n",
    "    filters = query_intent.get(\"filters\", {})\n",
    "    retrieved = retrieve_top_k(query, filters, k=10)\n",
    "    result = contextual_reasoning_qwen(query, retrieved)\n",
    "\n",
    "    print(\"Final Reasoning Result from Qwen:\\n\")\n",
    "    print(\"=\" * 50)\n",
    "    print(result[\"response\"].strip())  \n",
    "    print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in processing query intent: Expecting value: line 1 column 1 (char 0)\n",
      "Query Intent Result:\n",
      "{\n",
      "  \"filters\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"Show me beginner-friendly Python courses with rating above 4 with a focus on machine learning in Vietnamese.\"\n",
    "query_intent = get_query_intent(query)\n",
    "\n",
    "# Print the filters returned\n",
    "print(\"Query Intent Result:\")\n",
    "print(json.dumps(query_intent, indent=2))  # Checking the filters returned\n",
    "if query_intent.get(\"filters\"):\n",
    "    filters = query_intent.get(\"filters\", {})\n",
    "    retrieved = retrieve_top_k(query, filters, k=10)\n",
    "    result = contextual_reasoning_qwen(query, retrieved)\n",
    "\n",
    "    print(\"Final Reasoning Result from Qwen:\\n\")\n",
    "    print(\"=\" * 50)\n",
    "    print(result[\"response\"].strip())  \n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Response: model='qwen2.5:1.5b' created_at='2025-04-05T11:00:58.1934005Z' done=True done_reason='stop' total_duration=5874547600 load_duration=48698800 prompt_eval_count=215 prompt_eval_duration=85000000 eval_count=68 eval_duration=5733000000 message=Message(role='assistant', content='```json\\n{\\n  \"filters\": {\\n    \"category\": \"Python\",\\n    \"learning_path.suitable_for\": \"Beginner\",\\n    \"knowledge_requirements.prerequisites\": \"Basic programming knowledge and an interest in computer science.\",\\n    \"course_info.language\": \"Vietnamese\",\\n    \"rating\": \">4\"\\n  }\\n}\\n```', images=None, tool_calls=None)\n",
      "Query Intent Result:\n",
      "{\n",
      "  \"filters\": {\n",
      "    \"category\": \"Python\",\n",
      "    \"learning_path.suitable_for\": \"Beginner\",\n",
      "    \"knowledge_requirements.prerequisites\": \"Basic programming knowledge and an interest in computer science.\",\n",
      "    \"course_info.language\": \"Vietnamese\",\n",
      "    \"rating\": \">4\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def get_query_intent(query):\n",
    "    client = ollama.Client()\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "You are an AI assistant that extracts structured filters from course search queries.\n",
    "\n",
    "**Task:**\n",
    "- From the user's query, infer the best matching filters.\n",
    "- Match query terms like \"AI\" to \"Data Science\" if reasonable.\n",
    "- Only use the following attributes:\n",
    "  - \"title\"\n",
    "  - \"instructors\"\n",
    "  - \"category\"\n",
    "  - \"sub_category\"\n",
    "  - \"knowledge_requirements.teaches\"\n",
    "  - \"knowledge_requirements.prerequisites\"\n",
    "  - \"learning_path.suitable_for\"\n",
    "  - \"learning_path.career_paths\"\n",
    "  - \"course_info.language\"\n",
    "  - \"rating\"\n",
    "  - \"reviews.total_reviews\"\n",
    "- Output ONLY valid JSON like:\n",
    "  {\n",
    "    \"filters\": {\n",
    "      \"category\": \"Data Science\",\n",
    "      \"learning_path.suitable_for\": \"Beginner\"\n",
    "    }\n",
    "  }\n",
    "- If nothing matches, output {\"filters\": {}}\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"User Query: {query}\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat(model=\"qwen2.5:1.5b\", messages=messages)\n",
    "        print(\"Raw Response:\", response)  # Print the raw response to debug\n",
    "        \n",
    "        # Extracting the JSON content by removing the code block formatting\n",
    "        content = response['message']['content']\n",
    "        if content.startswith('```json') and content.endswith('```'):\n",
    "            json_content = content[7:-3].strip()  # Remove the '```json' and '```' parts\n",
    "        else:\n",
    "            json_content = content.strip()\n",
    "\n",
    "        # Now try to parse the cleaned JSON content\n",
    "        intent = json.loads(json_content)\n",
    "        return intent\n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"Error in processing query intent: {e}\")\n",
    "        return {\"filters\": {}}  # Fallback if parsing fails\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return {\"filters\": {}}\n",
    "\n",
    "# Test the function with a query\n",
    "query = \"Show me beginner-friendly Python courses with rating above 4 with a focus on machine learning in Vietnamese.\"\n",
    "query_intent = get_query_intent(query)\n",
    "print(\"Query Intent Result:\")\n",
    "print(json.dumps(query_intent, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Reasoning Result from Qwen:\n",
      "\n",
      "==================================================\n",
      "Currently, there are no beginner-friendly Python courses focused specifically on machine learning that have ratings over 4 stars available in Vietnamese. This makes it difficult to provide direct recommendations at the moment. However, I can suggest exploring other resources such as online platforms like Coursera or Udemy where you might find suitable courses with a higher rating. Additionally, local universities or community colleges offering introductory Python and machine learning courses could also be worth checking out for a Vietnamese-speaking audience.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "if query_intent.get(\"filters\"):\n",
    "    filters = query_intent.get(\"filters\", {})\n",
    "    retrieved = retrieve_top_k(query, filters, k=10)\n",
    "    result = contextual_reasoning_qwen(query, retrieved)\n",
    "\n",
    "    print(\"Final Reasoning Result from Qwen:\\n\")\n",
    "    print(\"=\" * 50)\n",
    "    print(result[\"response\"].strip())  \n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'Python',\n",
       " 'learning_path.suitable_for': 'Beginner',\n",
       " 'knowledge_requirements.prerequisites': 'Basic programming knowledge and an interest in computer science.',\n",
       " 'course_info.language': 'Vietnamese',\n",
       " 'rating': '>4'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Response: model='qwen2.5:1.5b' created_at='2025-04-05T11:29:15.6098549Z' done=True done_reason='stop' total_duration=6878169500 load_duration=30296500 prompt_eval_count=205 prompt_eval_duration=5084000000 eval_count=38 eval_duration=1755000000 message=Message(role='assistant', content='{\\n  \"filters\": {\\n    \"rating\": \">4\"\\n  },\\n  \"learning_path.suitable_for\": \"Beginner\",\\n    \"course_info.language\": \"French\"\\n}', images=None, tool_calls=None)\n",
      "Query Intent Result:\n",
      "{\n",
      "  \"filters\": {\n",
      "    \"rating\": \">4\"\n",
      "  },\n",
      "  \"learning_path.suitable_for\": \"Beginner\",\n",
      "  \"course_info.language\": \"French\"\n",
      "}\n",
      "Final Reasoning Result from Qwen:\n",
      "\n",
      "==================================================\n",
      "There were no courses with ratings above 4 stars that were specifically taught in French. To provide suggestions, I would need to look at specific course offerings or search within my database for any relevant courses offered in France. Would you like me to assist further?\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def get_query_intent(query):\n",
    "    client = ollama.Client()\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "You are an AI assistant that extracts structured filters from course search queries.\n",
    "\n",
    "**Task:**\n",
    "- From the user's query, infer the best matching filters.\n",
    "- Match query terms like \"AI\" to \"Data Science\" if reasonable.\n",
    "- Only use the following attributes:\n",
    "  - \"title\"\n",
    "  - \"instructors\"\n",
    "  - \"category\"\n",
    "  - \"sub_category\"\n",
    "  - \"knowledge_requirements.teaches\"\n",
    "  - \"knowledge_requirements.prerequisites\"\n",
    "  - \"learning_path.suitable_for\"\n",
    "  - \"learning_path.career_paths\"\n",
    "  - \"course_info.language\"\n",
    "  - \"rating\"\n",
    "  - \"reviews.total_reviews\"\n",
    "- Output ONLY valid JSON like:\n",
    "  {\n",
    "    \"filters\": {\n",
    "      \"category\": \"Data Science\",\n",
    "      \"learning_path.suitable_for\": \"Beginner\"\n",
    "    }\n",
    "  }\n",
    "- If nothing matches, output {\"filters\": {}}\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"User Query: {query}\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat(model=\"qwen2.5:1.5b\", messages=messages)\n",
    "        print(\"Raw Response:\", response)  # Print the raw response to debug\n",
    "        \n",
    "        # Extracting the JSON content by removing the code block formatting\n",
    "        content = response['message']['content']\n",
    "        if content.startswith('```json') and content.endswith('```'):\n",
    "            json_content = content[7:-3].strip()  # Remove the '```json' and '```' parts\n",
    "        else:\n",
    "            json_content = content.strip()\n",
    "\n",
    "        # Now try to parse the cleaned JSON content\n",
    "        intent = json.loads(json_content)\n",
    "        return intent\n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"Error in processing query intent: {e}\")\n",
    "        return {\"filters\": {}}  # Fallback if parsing fails\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return {\"filters\": {}}\n",
    "\n",
    "# Test the function with a query\n",
    "query = \"Courses above 4 stars rating taught in French.\"\n",
    "query_intent = get_query_intent(query)\n",
    "print(\"Query Intent Result:\")\n",
    "print(json.dumps(query_intent, indent=2))\n",
    "\n",
    "\n",
    "\n",
    "# ======== Step 6: (Optional) If needed, proceed to FAISS retrieval or other processing ========\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# ======== Step 1: Load SBERT Model ========\n",
    "sbert_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# ======== Step 2: Load Courses from JSON File ========\n",
    "with open('D:\\\\Thesis\\\\Courses-Searching\\\\src\\\\db\\\\processed_courses_detail.json', 'r', encoding='utf-8') as file:\n",
    "    courses = json.load(file)\n",
    "\n",
    "# ======== Step 3: Create FAISS Index (Embedding + Search) ========\n",
    "def create_faiss_index(courses, nlist=100):\n",
    "    course_texts = []\n",
    "    for course in courses:\n",
    "        title = course.get(\"title\", \"\")\n",
    "        description = course.get(\"description\", \"\")\n",
    "        instructors = course.get(\"instructors\", [])\n",
    "        if not isinstance(instructors, list):\n",
    "            instructors = [str(instructors)]\n",
    "        instructors = \", \".join(instructors)\n",
    "        knowledge_reqs = course.get(\"knowledge_requirements\", \"\")\n",
    "        course_info = course.get(\"course_info\", \"\")\n",
    "        text = f\"{title} {description} {instructors} {knowledge_reqs} {course_info}\"\n",
    "        course_texts.append(text)\n",
    "\n",
    "    embeddings = sbert_model.encode(course_texts, convert_to_numpy=True)\n",
    "    dimension = embeddings.shape[1]\n",
    "    \n",
    "    # Create FAISS index with IVF (Inverted File) index for faster retrieval\n",
    "    quantizer = faiss.IndexFlatL2(dimension)  # Flat index for quantization\n",
    "    index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_L2)\n",
    "    \n",
    "    # Train the index (required before adding data)\n",
    "    index.train(embeddings)\n",
    "    \n",
    "    # Add embeddings to the index\n",
    "    index.add(embeddings)\n",
    "    return index, embeddings\n",
    "\n",
    "\n",
    "faiss_index, embeddings = create_faiss_index(courses)\n",
    "\n",
    "# ======== Step 7: Retrieve Courses Using FAISS ========\n",
    "def retrieve_top_k(query, filters, k=10):\n",
    "    query_embedding = sbert_model.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = faiss_index.search(query_embedding, k)\n",
    "    retrieved_courses = [courses[idx] for idx in indices[0]]\n",
    "\n",
    "    filtered_courses = []\n",
    "    for course in retrieved_courses:\n",
    "        match = True\n",
    "        for key, value in filters.items():\n",
    "            if key in course:\n",
    "                # Use fuzzy matching to allow partial matches (case-insensitive)\n",
    "                course_value = str(course[key]).lower()\n",
    "                if fuzz.partial_ratio(value.lower(), course_value) < 80:  # Adjust threshold as needed\n",
    "                    match = False\n",
    "                    break\n",
    "        if match:\n",
    "            filtered_courses.append(course)\n",
    "\n",
    "    return filtered_courses[:k]\n",
    "\n",
    "\n",
    "\n",
    "# ======== Step 8: Generate Final Response Using Qwen ========\n",
    "def contextual_reasoning_qwen(query, retrieved_courses):\n",
    "    prompt = f\"\"\"\n",
    "You are an AI assistant helping to answer course-related questions.\n",
    "\n",
    "**User Query:**\n",
    "{query}\n",
    "\n",
    "**Retrieved Courses:**\n",
    "{json.dumps(retrieved_courses, indent=2)}\n",
    "\n",
    "Provide a brief reasoning and final suggestion.\n",
    "\"\"\"\n",
    "    try:\n",
    "        client = ollama.Client()\n",
    "        response = client.generate(model=\"qwen2.5:1.5b\", prompt=prompt)\n",
    "        return {\"response\": response.response}\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return {\"response\": \"An error occurred while processing the response.\"}\n",
    "\n",
    "\n",
    "# ======== Step 9: Execute the Full Pipeline ========\n",
    "if query_intent.get(\"filters\"):\n",
    "    filters = query_intent.get(\"filters\", {})\n",
    "    retrieved = retrieve_top_k(query, filters, k=10)\n",
    "    result = contextual_reasoning_qwen(query, retrieved)\n",
    "\n",
    "    print(\"Final Reasoning Result from Qwen:\\n\")\n",
    "    print(\"=\" * 50)\n",
    "    print(result[\"response\"].strip())  \n",
    "    print(\"=\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
